IEEE INTERNET OF THINGS JOURNAL, VOL. 9, NO. 4, FEBRUARY 15, 2022 2787
Toward Lightweight, Privacy-Preserving
Cooperative Object Classiﬁcation for
Connected Autonomous Vehicles
Jinbo Xiong ,Member, IEEE , Renwan Bi, Youliang Tian ,Member, IEEE ,
Ximeng Liu ,Senior Member, IEEE , and Dapeng Wu ,Senior Member, IEEE
Abstract —Collaborative perception enables autonomous vehi-
cles to exchange sensor data among each other to achieve cooper-ative object classiﬁcation, which is considered an effective meansto improve the perception accuracy of connected autonomousvehicles (CA Vs). To protect information privacy in coopera-
tive perception, we propose a lightweight, privacy-preserving
cooperative object classiﬁcation framework that allows CA Vs toexchange raw sensor data (e.g., images captured by HD camera),without leaking private information. Leveraging chaotic encryp-tion and additive secret sharing technique, image data are ﬁrstencrypted into two ciphertexts and processed, in the encryptedformat, by two separate edge servers. The use of chaotic map-ping can avoid information leakage during data uploading.The encrypted images are then processed by the proposedprivacy-preserving convolutional neural network (P-CNN) modelembedded in the designed secure computing protocols. Finally,the processed results are combined/decrypted on the receivingvehicles to realize cooperative object classiﬁcation. We formallyprove the correctness and security of the proposed frameworkand carry out intensive experiments to evaluate its performance.The experimental results indicate that P-CNN offers exactly
Manuscript received April 1, 2021; revised May 24, 2021; accepted
June 15, 2021. Date of publication June 30, 2021; date of current ver-
sion February 4, 2022. This work was supported in part by the National
Natural Science Foundation of China under Grant 61872088, Grant 61772008,Grant 62072109, Grant 61872090, Grant U1905211, Grant U1804263, andGrant U1836205; in part by the Natural Science Foundation of Fujian
Province under Grant 2019J01276; in part by the Science and Technology
Major Support Program of Guizhou Province under Grant 20183001; inpart by the Science and Technology Program of Guizhou Province under
Grant 20191098; in part by the Guangxi Key Laboratory of Cryptography and
Information Security under Grant GCIS202105; and in part by the Project ofHigh-level Innovative Talents of Guizhou Province under Grant 20206008.(Corresponding author: Youliang Tian.)
Jinbo Xiong and Renwan Bi are with the Fujian Provincial Key Laboratory
of Network Security and Cryptology, College of Computer and CyberSecurity, Fujian Normal University, Fuzhou 350117, China, and also withthe Guangxi Key Laboratory of Cryptography and Information Security,
Guilin University of Electronic Technology, Guilin 541004, China (e-mail:
jbxiong@fjnu.edu.cn; brw2806@163.com).
Youliang Tian is with the State Key Laboratory of Public Big Data, College
of Computer Science and Technology, Guizhou University, Guiyang 550025,
China (e-mail: youliangtian@163.com).
Ximeng Liu is with the Key Laboratory of Information Security of
Network Systems, Fuzhou University, Fuzhou 350108, China (e-mail:snbnix@gmail.com).
Dapeng Wu is with the Chongqing Key Laboratory of Optical
Communication and Networks, Chongqing University of Postsand Telecommunications, Chongqing 400065, China (e-mail:
wudapengphd@gmail.com).
Digital Object Identiﬁer 10.1109/JIOT.2021.3093573almost the same object classiﬁcation results as the original CNN
model, while offering great privacy protection of shared data andlightweight execution efﬁciency.
Index Terms —Connected and autonomous vehicle, convolu-
tional neural network (CNN), edge computing, object classiﬁ-cation, privacy protection.
I. I NTRODUCTION
THANKS to the perfect combination of foremost wireless
communication and autonomous vehicle technologies, a
connected autonomous vehicle (CA V) system plays an impor-
tant role in facilitating our daily life, e.g., accomplishingreal-time tasks, talking with the business, and working in a
mobile environment [1]. Typically, in a CA V system, each
autonomous vehicle leverages a suite of local sensors [e.g.,high-deﬁnition (HD) cameras] to perceive its surrounding envi-
ronment [2], [3]. The perception results, e.g., nearby objects’
locations (and types), can be shared among vehicles to realize
cooperative perception [4], and achieve a CA V system.
A. Problem Statement
It has been discovered recently that sharing raw sensor
data, instead of processed ones, among autonomous vehiclescould signiﬁcantly improve the performance of object detec-
tion in a CA V system [5]. The basic idea is to let edge servers
collect the raw sensor data, e.g., produced by HD camera
sensors, from nearby autonomous vehicles to conduct more
accurate cooperative object detection [6]. Sharing raw per-ception data among vehicles or between vehicles and edge
servers, however, faces serious privacy leakage issues, due to
the fact that the captured data contain a large amount of sen-sitive information [7], [8]. For example, image data captured
by HD cameras may contain drivers’ or pedestrians’ faces,
licence plates, roadside buildings, and location information [9].How to protect these sensitive information will bring great
challenges to the CA V system [10]. The existing data pri-
vacy protection methods, such as anonymity, obfuscation,and cryptography, will create serious problems, reducing data
availability and identiﬁcation accuracy, and increasing tremen-
dous computational cost. Therefore, it is a profound issueto design a lightweight, privacy-preserving cooperative object
detection/classiﬁcation mechanism for CA Vs.
2327-4662 c/circlecopyrt2021 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.
See https://www.ieee.org/publications/rights/index.html for more information.
Authorized licensed use limited to: Univ of  Calif San Diego. Downloaded on July 19,2022 at 20:42:05 UTC from IEEE Xplore.  Restrictions apply. 2788 IEEE INTERNET OF THINGS JOURNAL, VOL. 9, NO. 4, FEBRUARY 15, 2022
B. Limitation of Prior Arts
Convolutional neural network (CNN) [11] is a standard art
for image classiﬁcation. However, training a high accuracyCNN model for the CA V system is usually very com-
plex, requiring huge computational cost and storage capacity.
Therefore, due to the computation-intensive nature of dataprocessing based on CNN for the CA V system, cooperative
perception among vehicles is usually implemented by ofﬂoad-
ing complex computational tasks from autonomous vehiclesto edge servers [12], [13]. This is particularly true when sen-
sor data from several vehicles are fused by the edge servers
to realize a cooperative object detection [14]. As information
is leaving capturing vehicles, privacy protection of captured
sensor data must be placed in order to take the full advantageof edge computing [15], [16].
In this regard, sending raw data directly to edge server for
processing is obviously impractical and insecure [17]. Majorityof existing security solutions leverage data encryption tech-
niques [18], i.e., sensor data are encrypted before transmission,
and decrypted and processed after reception. A sending vehicleencrypts its sensor data and transmits it to a receiving vehicle
in the ciphertext to ensure data security during the transmis-
sion process. It is still possible for privacy leakage after thedata are decrypted on receivers/edge servers. To address this
issue, homomorphic encryption (HE) [19] is undoubtedly the
best choice because data processing can be carried out overciphertexts, without the need of knowing plaintext information.
CryptoNets [20] and CryptoDL [21] employed additively HE
(AHE) to realize simple computation tasks involved in neuralnetworks. Later, Juvekar et al. [22] used AHE and garbled
circuit-based two-party computation to improve computing
efﬁciency to some extent. Unfortunately, the computational
cost and processing latency brought by HE are still over-
burdened for CA V applications. More importantly, the rawperception data are fully exposed to the receiving vehicle,
and once the vehicle is compromised, the consequences are
terrible.
C. Proposed Solution
In order to solve the above-mentioned problems, we employ
a more lightweight additive secret sharing (ASS) scheme toimplement the computational operations involved in a CNN,
using a two-tier edge architecture [23], [24], to ofﬂoad heavy
object classiﬁcation tasks from autonomous vehicles to twoedge servers. In this way, edge servers are able to process
encrypted images by using the proposed privacy-preserving
CNN (P-CNN) to accomplish cooperative object classiﬁcation.
To ensure the secure storage and transmission of image
data [25], it is necessary to implement an effective image
encryption processing. As such, a sending vehicle ran-
domly splits the original image, captured by HD cameras
on autonomous vehicles, into two image shares with thesame dimension. Then, these two shares are encrypted and
transmitted to two edge servers using chaotic maps to avoid
information leakage caused by simultaneous channel attacks.These edge servers conduct privacy-preserving operations
within a CNN to discover and detect objects on encryptedimage shares, and collaboratively perform the cooperative
object classiﬁcation task. In the entire process, image privacyis always protected; in addition, the computational cost and
communication overhead are ofﬂoaded to edge servers.
D. Contributions
The major contributions of this article can be summarized
as follows.
1) We propose a lightweight, privacy-preserving framework
that is speciﬁcally designed to realize a cooperativeobject classiﬁcation in CA V systems. In the frame-
work, image reencryption, privacy-preserving CNN, and
object decryption are aiming to achieve secure and efﬁ-cient cooperative object classiﬁcation for CA Vs. This
is a generic framework since it can be extended to
other CNN-based deep learning models, as long as the
computation tasks involved in these models are equiv-
alently implemented by the proposed secure computingprotocols.
2) Before the raw perception data are uploaded to the edge
server, an image chaotic encryption scheme is designedto prevent potential adversaries from hijacking sending
vehicles or simultaneous damaging both upload links. If
both links are compromised by the adversary, the origi-nal images can be easily recovered by addition operation
since they are randomly split by ASS.
3) A series of secure computing protocols is designed
in P-CNN to (almost) identically implement the
computational operations associated with the original
CNN. Moreover, these protocols are well suited formultidimensional arrays. As a result, the computational
efﬁciency of P-CNN is greatly improved, when com-
pared to the elementwise calculations.
4) As one of the heaviest computational tasks, encrypted
image-based processing is carried out on edge servers.Therefore, the computational cost on individual vehicle
is signiﬁcantly reduced. CA Vs, in contrast, only perform
simple addition calculations. Thorough theoretical anal-ysis proves the security and correctness of the proposed
protocols and framework. Comprehensive experimental
results further verify that our framework is superior tothe existing schemes in terms of computational cost and
communication overhead.
The remainder of this article is organized as follows. In
Section II, we introduce the necessary preliminaries. The
system architecture and security model are presented in
Section III. In Section IV, we discuss in detail the imple-mentation process of the proposed framework, and describe
some secure computing protocols involved in P-CNN based
on the ASS. Theoretical analysis and experimental resultsare presented in Sections V and VI, respectively. Section VII
introduces the related work, and Section VIII summarizes the
article.
II. P
RELIMINARIES
In this section, we introduce some necessary knowledge,
including chaos map, CNN model, and ASS.
Authorized licensed use limited to: Univ of  Calif San Diego. Downloaded on July 19,2022 at 20:42:05 UTC from IEEE Xplore.  Restrictions apply. XIONG et al. : TOWARD LIGHTWEIGHT, PRIV ACY-PRESERVING COOPERATIVE OBJECT CLASSIFICATION 2789
Fig. 1. Major operations in the CNN model, followed by the corresponding functions.
A. Chaotic Map
Chaos [26] is a phenomenon that appears to be random and
irregular motion in a certain system. The map sequence based
on the chaos theory is very sensitive to the control param-eters and initial values. This statistical characteristics can
be used to design image diffusion and obfuscation schemes.
Moreover, compared with image iterative encryption based on
symmetric keys, the chaotic encryption method has lower com-
putational cost and is more consistent with image encryptionand transmission in the context of CA V .
Here, we introduce two discrete chaotic maps: 1) logis-
tic map [27] and 2) lorenz map [28]. The logistic map is aclassical 1-D discrete map, which is deﬁned as φ(k+1)=
εφ(k)(1−φ(k)), where εis the control parameter. When
3.57<ε≤4, the map is chaotic. The lorenz map is a 3-D
discrete map, which is deﬁned as
⎧
⎨
⎩ξ
1(k+1)=ξ1(k)ξ2(k)−ξ3(k)
ξ2(k+1)=ξ1(k)
ξ3(k+1)=ξ2(k).(1)
It is worth noting that the image encryption scheme based
on single map is slightly weak in security strength. Obviously,
it is reasonable to combine the above two maps to design
a higher key-dimensional image encryption scheme without
signiﬁcantly increasing computational cost. See Section IV-A1for the construction process.
B. CNN Model
The CNN model widely used for object classiﬁcation tasks
usually contains several convolutional (CONV) layers, activa-tion (ACT) layers, pooling (POOL) layers, and full-connected
(FC) layers, as shown in Fig. 1. Below, we introduce the major
functions and operations involved in the four types of layers.
For the CONV layer, the main purpose is to extract local
features from images. Essentially, the underlying calculation
can be viewed as a linear combination of the data from imagesand the convolutional core. Assuming the input and output is
xandy, respectively, we denote y
j,k=/Sigma1C,C
m/prime,m/prime/prime=1,1xj+m/prime,k+m/prime/prime·
wm/prime,m/prime/prime+b, where (w;b)denotes shared weights and biases
of convolutional core, and the size of convolutional core isC×C.
The ACT layer is used to increase the nonlinear expres-
sion ability of the model. Therefore, nonlinear computationis involved in this layer. The activation function involved
in the VGG16 model [11] is the rectiﬁed linear unit [i.e.,
ReLU(y)=max(x,0)].The POOL layer is responsible for feature selection, i.e., a
downsampling region is replaced by a single value. The maxi-
mum pooling (MAX-POOL) used in the VGG16 model takesthe maximum value as the output ( x
δ,δ=arg max {xj,j=
1,..., P×P}).
For the FC layer, the goal is to map features to labeled sam-
ples, i.e., making the ﬁnal classiﬁcation decision. Each neuron
in this layer is connected to all neurons in the anterior layer,
and each link contains weight and bias parameters. Similar
to the CONV layer, the core calculation is also a pure linear
combination, i.e., yj=/Sigma1F
kwj,k·xk+b, where Fis the number
of neurons in the former layer.
C. Additive Secret Sharing
Secret sharing [29] is deﬁned as follows. The trusted party
divides a secret into Nshares, which are kept by Npartic-
ipants, respectively. No less than k(k≤N)participants can
reconstruct the complete secret. Somewhat differently, there
are only two participants in the ASS [30], i.e., N=k=2.
The purpose of ASS is no longer limited to key management,
but also can be used to protect all secrets contained in the
integer domain.
In this article, we consider the array as minimum comput-
ing unit, and all elements are in the integral domain Zn, where
nrepresents the size of Zn. The two edge servers S1andS2
execute all proposed protocols independently or cooperatively.
Here, we introduce some basic secure protocols for linear cal-
culation, mainly secure addition/subtraction (SecAdd/SecSub)
and secure scalar multiplication (SecSMul) protocols, leverag-
ing ASS. The input array (u,v)∈Znof the SecAdd/SecSub
protocol is split into (u1,v1)and(u2,v2), and sent to S1and
S2, respectively. Independently, S1calculates f1=u1±v1
andS2calculates f2=u2±v2. The simple addition of f1and
f2gives the same result as the original addition/subtraction,
because f1+f2=u±vis always true. Similar to the
SecAdd/SecSub protocol, the input array (p,q)∈Znof the
SecSMul protocol is divided into (p1,q)and(p2,q), and S1
andS2calculate f1=q·p1and f2=q·p2, respectively.
Obviously, f1+f2=p·q.
III. S YSTEM ARCHITECTURE AND SECURITY MODEL
A. System Architecture
In the proposed framework, there are three major
components: 1) CA Vs (sending vehicles V1and receiving
Authorized licensed use limited to: Univ of  Calif San Diego. Downloaded on July 19,2022 at 20:42:05 UTC from IEEE Xplore.  Restrictions apply. 2790 IEEE INTERNET OF THINGS JOURNAL, VOL. 9, NO. 4, FEBRUARY 15, 2022
Fig. 2. System architecture of the privacy-preserving object classiﬁcation
for CA Vs.
vehicles V2); 2) two edge servers ( Si,i=1,2); and 3) a
semitrusted lightweight server ( T), as shown in Fig. 2.
1)T:Tis responsible for generating the key for image
encryption and transmitting it to the sending vehicle V1
andSithrough the secure channel. Moreover, Tprovides
the random array for Sito process the image/feature
array.
2)V1:V1perceives its surrounding environment, using HD
sensors, and generates image data. Each image Iis ran-
dom split into two image shares Ii(i.e., I=I1+I2).
Then, V1encrypts them as encrypted images Bi, and
sends them to Si, respectively, so that Biare not directly
exposed to the communication link.
3)Si:Before image processing, Siﬁrst needs to perform
a round of decryption calculations to recover Ii. Then,
Siexecutes the P-CNN model by using a serial secure
computing protocols and obtains two classiﬁcation result
Oi, respectively.
4)V2:After receiving Oi,V2only needs to perform simple
addition calculation to recover the original classiﬁcation
results from the encrypted feature (i.e., O=O1+O2).
B. Security Model
In this article, we discuss the privacy-preserving inference
process over encrypted image. The parameters of the neural
network model are private to Siand cannot be known by V1;
The raw image, features extracted by Siand ﬁnal classiﬁcation
result are private to V1and cannot be known by Si.
Similar to many existing literatures [23], [24], [31]–[33],
we adopt a semihonest security model. Tand Siare con-
sidered as honest-but-curious (HBC) entities. They strictly
follow the implementation protocol and are interested in the
secret information owned by other entities. At the same time,
we assume that TandSiare independent and do not col-
lude with each other [23], [24]. In practice, this assumptionoften manifests itself as S
1andS2belonging to different or
even competitive companies, such as Huawei’s TaiShan@Edge
and Microsoft Azure IoT Edge, as well as Tcan serve by
some neutral agency. Since it is only responsible for gener-
ating/distributing encryption key and random array by securechannel in ofﬂine, Tdoes not participate in the online cal-
culation. This means that Tdoes not receive/possess any
meaningful image data, and does not affect framework secu-
rity. Moreover, we also assume that the effective vehicles Vi
sharing data are always reliable and the communication link
do not be dropped.
In the semihonest model, there are many potential proba-
bilistic polynomial time (PPT) adversaries Aaimed at obtain-
ing the image privacy captured by Viusing the onboard
equipment. Ahas the following capabilities and constraints:
1)Acan corrupt the sending vehicles and receiving vehicles
to obtain the stored encrypted data, yet not obtain encryption
key; 2) Acan eavesdrop all communication links to obtain
transmitted information, including image data sent by send-
ing vehicle to edge servers and classiﬁcation results sent by
edge servers to receiving vehicle; 3) Acan only corrupts and
obtain the information of at most one of two edge servers;
and 4) Acannot eavesdrop the secure channel between T,
S1, and S2, and cannot corrupt T. The success of Aattacking
means that the complete original image or feature is obtained.
This is actually quite difﬁcult, as detailed security analysis is
illustrated in Section V-C.
IV . P RIV ACY -PRESERVING OBJECT
CLASSIFICATION FOR CA V
In this section, we describe the entire operation processes
of the proposed privacy-preserving object classiﬁcation frame-
work in detail.
A. Image Reencryption
For the resisting simultaneous channel attack, this article
introduces additional image encryption operation while ran-
domly splitting the image in the image upload stage. Even
if adversaries Aare able to capture both upload links at the
same time, the original image Icannot be recovered with-
out knowing the encryption key. In fact, the process of image
reencryption consists of two stage: 1) image split and 2) image
confusion (i.e., real image encryption). First, V1random splits
each frame of its image into two images shares Iileveraging
ASS technologies. Then, V1reencrypts Iiinto two encrypted
images Bi. In order to not signiﬁcantly increase the image
upload cost, the image encryption scheme based on the chaos
theory is designed to overcome this issue. Below, we illustrate
the process of key generation and encryption of this scheme.
1) Key Generation: Combining logistic map and lorenz
map, we construct a new efﬁcient 3-D discrete chaotic map,as shown in formula (2), for generating encryption keys. The
inputs tuple (γ
1(0),γ2(0),γ3(0))are within in the interval
(0,1),(−5,5), and(−60,60), respectively. In order to make
the constructed chaotic map in the chaotic state, we set its con-
trol parameter tuple (ε1,ε2,ε3)as(3.7,0.5,0.3). After 4000
iterations, we can clearly observe that the constructed chaotic
mapping sequence is almost disordered, and it is difﬁcult to
infer a trace of objective law, as shown in Fig. 3
⎧
⎨
⎩γ1(k+1)=ε1γ1(k)−γ12(k)
γ2(k+1)=ε2γ2(k)γ3(k)−ε3γ3(k)
γ3(k+1)=γ1(k)+γ2(k).(2)
Authorized licensed use limited to: Univ of  Calif San Diego. Downloaded on July 19,2022 at 20:42:05 UTC from IEEE Xplore.  Restrictions apply. XIONG et al. : TOWARD LIGHTWEIGHT, PRIV ACY-PRESERVING COOPERATIVE OBJECT CLASSIFICATION 2791
Fig. 3. Trajectory of our 3-D chaotic map after 4000 iterations. (a) γ1
sequence. (b) γ2sequence. (c) γ3sequence.
Fig. 4. Distribution of 4000 randomly selected from extended chaotic
sequences. (a) δ1sequence. (b) δ2sequence.
Assuming the image size is (τ1,τ2,τ3), we iterate the
chaotic map in formula (2) for τ1τ2τ3times, using the input
(γ1(0),γ2(0),γ3(0))=(0.5,0.5,0.5). As a result, three
chaotic sequences γ1,γ2, and γ3with length τ1τ2τ3are
generated. Theoretically, the resulting chaotic sequence is
aperiodic, but in practice, this assumption is very harsh.Therefore, we use a kind of sinusoidal function to deal with
the above sequences, and then obtain a longer period of
chaotic sequence ϕ
1=sin2(γ1)andϕ2=sin2(γ2+γ3)/2
in the interval [0 ,1]. In order to obfuscate image pixel val-
ues, these sequence values are obviously too small and it is
necessary to further generalize them to the entire pixel space
[0,255]. The transform δ1=(round(1016ϕ1)mod 256 and
δ2=(round(1016ϕ2))mod 256 are performed, where 1016
is the extended period. Without loss of generality, we ran-
domly selected 4000 sequence values, and it can be seen from
Fig. 4 that values of δ1andδ2sequences are approximately
randomly distributed in pixel interval [0 ,255]. Therefore, we
choose these two sequences δ1andδ2as the initial encryption
keys.
2) Encryption: Similar to the generated key, the images
Ii(i=1,2)sent to S1and S2are stretched into stream
sequence of length τ1·τ2·τ3. In order to make the encrypted
image more sensitive, that is, to increase the dependency
between ciphertext and plaintext-key pairing, we performed
two rounds of encryption calculation sequentially, as illus-
trated in
⎧
⎨
⎩Pi(1)=Ii(1)⊕δ1(1)
Pi(k)=((Ii(k)+δ1(k−1))mod 256 )⊕
((δ1(k)+Pi(k−1))mod 256 )(3)
⎧
⎨
⎩Bi(1)=Pi(1)
Bi(k)=(Pi(k))⊕((Bi(k−1)+δ2(k)mod 256 )
⊕δ2(k−1)).(4)
Fig. 5. Visual effect of encrypting and decrypting original image and two ran-
domly segmented images. The top row belongs to I, the middle row belongs
toI1, and the bottom row belongs to I2. (a) Original image. (b) Encrypted
image. (c) Recovered image.
Pi(i=1,2)are encrypted sequence after the ﬁrst round of
encryption, while Biare encrypted sequence after the second
round of encryption. Modular and XOR operations are per-
formed on unsigned integers and, importantly, are reversible.
As shown in Fig. 5, the original image Iis randomly split
intoIi.
It is obvious that only image Iicannot reveal any one pixel
value, however, Ican be recovered if both I1and I2are
obtained at the same time. After two rounds of calculation, theimages I
iare encrypted as Bi. Even if the adversary master
B1andB2, it is unrealistic to decrypt and obtain Iwithout
the correct key.
B. Image Processing With P-CNN
After receiving encrypted images Bi,Siﬁrst needs to per-
form the reverse operation of encryption to recover the two
image shares Ii. Speciﬁcally, the ﬁrst round of decryption is
the reverse operation of the second round of encryption, and
the second round of decryption is the reverse operation of the
ﬁrst round of encryption. The decryption key δ1andδ2are pro-
vided by T(see in Fig. 2), and the decryption is calculated
as illustrated in formulas (5) and (6). As shown in Fig. 5(c),
Sican recover Ii
⎧
⎨
⎩Pi(k)=(Bi(k))⊕((Bi(k−1)+δ2(k)mod 256 )
⊕δ2(k−1))
Pi(1)=Bi(1)(5)
⎧
⎨
⎩Ii(k)=(Pi(k)⊕(Pi(k)+δ1(k−1)mod 256 )
−δ1(k−1))mod 256
Ii(1)=Pi(1)⊕δ1(1).(6)
Authorized licensed use limited to: Univ of  Calif San Diego. Downloaded on July 19,2022 at 20:42:05 UTC from IEEE Xplore.  Restrictions apply. 2792 IEEE INTERNET OF THINGS JOURNAL, VOL. 9, NO. 4, FEBRUARY 15, 2022
Fig. 6. Dependency relationship of protocols.
Afterward, Sicollaboratively executes P-CNN over Iito
extract ciphertext features, and ﬁnally obtain two classiﬁcationshares O
i. We mainly introduce the implementation process of
each network layers in CNN. In view of the application scope
of ASS, for each ﬁxed-point number u, we multiply it with
10κ, and transform it into uin integer domains Znthrough
⌊u·10κ⌋. In the absence of special instructions, the overline
is omitted as follows.
Next, we mainly discuss the secure implementation meth-
ods of CONV layer, ReLU layer, MAX-POOL layer, and FClayer in P-CNN. In order to facilitate the understanding, the
dependency relationship of protocols proposed in this article is
shown in Fig. 6. Secure bitwise transformation from AND to
XOR (SecBitTrans), secure comparison (SecComp), and secure
multiplication (SecMul) [24] protocols is the component of the
secure rectiﬁed linear unit (SecReLU) protocol.
1) Secure CONV and FC Layer: Since the CONV layer
involves only linear operations, i.e., matrix dot product, theidea of ASS can be used directly. The 2-D convolution oper-
ation is shown in formula (7), where xrepresents feature
matrix of size (d
1,d2),wrepresents convolution kernel weight
of size (e1,e2), and brepresents convolution kernel bias. As
the convolution kernel slides across x(from left to right and
from top to bottom), xexpands to ¯x, and the convolution
operation can be viewed as the dot product of the subma-
trix in ¯xwith w, ﬁnally returning convolution result yof size
(d1−e1+1,d2−e2+1). In P-CNN, xis split into two random
shares xi(i.e., ¯xi). Adopting the SecSMul protocol, Siindivid-
ually computes yi=SecAdd (SecSMul (¯xi,w),b). Obviously,
y=y1+y2holds in any case
Conv⎛
⎝x=⎡
⎣x1x2x3
x4x5x6
x7x8x9⎤
⎦,/parenleftbigg
w=/bracketleftbiggw1w2
w3w4/bracketrightbigg
,b/parenrightbigg⎞
⎠
=⎛
⎜⎜⎝¯x=⎡
⎢⎢⎣/bracketleftbiggx1x2
x4x5/bracketrightbigg/bracketleftbiggx2x3
x5x6/bracketrightbigg
/bracketleftbiggx4x5
x7x8/bracketrightbigg/bracketleftbiggx5x6
x8x9/bracketrightbigg⎤
⎥⎥⎦⎞
⎟⎟⎠⊙w+b
=/bracketleftbiggx1w1+···+ x5w4x2w1+···+ x6w4
x4w1+···+ x8w4x5w1+···+ x9w4/bracketrightbigg
=y.(7)
Similar to the CONV layer, the FC layer contains dot
product operation. Given public connected weight and feature
vector share, Sican locally compute dot product result share
by invoking the SecSMul protocol.Protocol 1: Secure Bitwise Transformation From AND to
XOR (SecBitTrans)
Input :Si(i=1,2)hasui∈Zn.
Output :Sioutputs fi.
1Trandomly generates μi∈Zn, computes θ←μ1⊗μ2,
and randomly splits θ←θ1⊕θ2;
2Tsends μiandθitoSi;
3Sicomputes ηi←ui⊕μi, and sends ηitoS3−i;
4S1computes f1←θ1⊕(μ1⊗η2),S2computes
f2←θ2⊕(μ2⊗η1)⊕(η1⊗η2);
5Sireturns fi.
Protocol 2: SecComp
Input :Sihasui∈Zn.
Output :Sioutputs fi.
1forj=0,···,l−1do
2 Sijointly compute χ(j)
i←SecBitTrans (u(j)
1,u(j)
2);
3Silocally computes f(0)
i←u(0)
iandc(0)
i←χ(0)
i;
4forj=1,···,l−1do
5 Sijointly compute α(j)
i←SecBitTrans (u(j)
1,c(j−1)
2)
andβ(j)
i←SecBitTrans (c(j−1)
1,u(j)
2);
6 Silocally computes
f(j)
i←(u(j)
i⊗c(j−1)
i)⊕χ(j)
i⊕α(j)
i⊕β(j)
i;
7Sireturns f(l−1)
i.
2) Secure ReLU Layer: The ReLU function in CNN is used
to selectively activate features; in other word, the goal is to
suppress features less than zero, i.e., computing max (x,0).
The problem is how to design SComp so that Sican coop-
eratively compute the relationship between xand 0 without
revealing the real features x. In fact, this can be reduced to a
positive–negative decision problem. To get most signiﬁcant bit
(MSB) sharing, we simply need to convert the addition shar-
ing to exclusive-or ( XOR) sharing. Using bool circuit, we can
achieve bitwise addition operation with carry. Additionally, we
specially design the SecBitTrans protocol based on ASS tech-
nology to provide carry for the above bitwise addition, aimingto convert the AND sharing to
XOR sharing for single bit.
The construction of SecBitTrans protocol is shown in
Protocol 1. Given input array shares ui(i=1,2), participating
in the calculation in the form of complement, the goal of the
SecBitTrans protocol is to get fi, satisfying f1⊕f2=u1⊗u2.
Adopting the idea of Beaver triple [34], Testablishes the rela-
tionship between μiandθi, such that θ1⊕θ2=μ1⊗μ2
(line 1). Among them, ⊕represents XOR operation, and
⊗represents AND operation. Note that these random num-
bers are selected from group Zn, where the bit length of
nis typically 16, 32, or 64 bit, depending on the security
requirement of the protocol. Then, Sihides uiinηibefore
sending to S3−i; Finally, Siconverts AND sharing uiinto XOR
sharing fi.
The detailed construction is shown in Protocol 2. Given
input array shares ui(i=1,2), participating in l-bit com-
plement form u(l−1,...,0)
i, SecComp protocol is objective to
Authorized licensed use limited to: Univ of  Calif San Diego. Downloaded on July 19,2022 at 20:42:05 UTC from IEEE Xplore.  Restrictions apply. XIONG et al. : TOWARD LIGHTWEIGHT, PRIV ACY-PRESERVING COOPERATIVE OBJECT CLASSIFICATION 2793
Protocol 3: SecReLU
Input :Sihas input feature xi∈Zn.
Output :Sioutputs activation feature yi.
1Sijointly compute (ζ1,ζ2)←SecComp (x1,x2);
2Sijointly compute (s1,s2)←SecMul (ζ1,0,ζ2,1);
3S1locally computes ti←ζi+si;
4Sijointly compute (y1,y2)←SecMul (x1,1−t1,x2,−t2);
5Sireturns yi.
Protocol 4: SecMaxPool
Input :Sihas input feature xi∈Zn.
Output :Sioutputs max-pooling feature yi.
1foreach pooling region R do
2 Siinitialize b1,b2←0;
3 forj,ki n(0,0)→(1,1)do
4 Sicomputes λi←xR
i(b1,b2)−xR
i(j,k), and
sends λ1toS3−i;
5 Silocally computes λ←λ1+λ2;
6 ifλ< 0then
7 Siassign b1←jandb2←k;
8 Sicomputes yR
i←xR
i(b1,b2);
9Sireturns yi.
output fi, satisfying f1⊕f2=u1+u2.F i r s t , Sijointly
computes the carry result sharing χ(l−1,...,0)
iwithout carry
(lines 1 and 2). For the least signiﬁcant bit (LSB), f(0)
iand
c(0)
iare the addition result sharing and carry result sharing,
respectively (line 3). Where j=1,..., l−1, it satisﬁes
c(j)
1⊕c(j)
2←(u(j)
1⊗u(j)
2)⊕((u(j)
1⊕u(j)
2)⊗(c(j−1)
1⊕c(j−1)
2))
andf(j)
1⊕f(j)
2←(u(j)
1⊕u(j)
2)⊕(c(j−1)
1⊕c(j−1)
2);Sican obtain
f(l−1,...,0)
iby invoking the SecBitTrans protocol (lines 4–6).
According to the MSB shares fl−1
i, we can infer the sign
of input. Obviously, if fl−1
1⊕fl−1
2=0, then u1+u2≥0;
otherwise, u1+u2<0.
Therefore, we design the SecReLU protocol that embed the
SComp protocol to realize the same effect as normal ReLUfunction. As illustrated in Protocol 3, given the input feature
x
1and x2(i.e., x=x1+x2),Sicooperatively obtains the
XOR shares ζiof MSB by applying the SecBitExtra proto-
col (line 1). However, passing the MSB shares directly can
reveal the distribution of activation features. In order to pro-
tect distribution privacy, the XOR sharing ζiof MSB is usually
converted to additive sharing ti(lines 2 and 3), subjected to
t1+t2=ζ1+ζ2+ζ1·ζ2=ζ1⊕ζ2. Among them, the
SecMul [24] protocol is based on Beaver triples [34]. Usingthe SecMul protocol again, S
ican obtain ReLU shares yi,s a t -
isfying y1+y2=(x1+x2)·(1−(t1+t2)).I ft1+t2=0, then
y1+y2=x1+x2; otherwise, y1+y2=0.
3) Secure MAX-POOL Layer: The goal of the MAX-POOL
layer is to calculate max {x(j,k),j,k=0,1}. To avoid dis-
closing feature privacy to Si, we designed a secure maximum
pooling protocol (SecMaxPool) adopting the idea of ASS tech-
nology, as illustrated in Protocol 4. Given the input feature xi,
Fig. 7. Simple instance of Fast-MaxPool protocol.
Protocol 5: Fast-SecMaxPool
Input :Sihas four-dimensional feature xi∈Zn.
Output :Sioutputs max-pooling feature yi.
1Siperforms transpose xi←xi.transpose (2,3,0,1);
2Siblocks xiinto(x(0,0)
i,x(0,1)
i,x(1,0)
i,x(1,1)
i)according to
the odd-even index;
3Sijointly compute
(y1,y2)←where(((x(0,0)
1−x(0,1)
1)+(x(0,0)
2−x(0,1)
2)) <
0,((x(0,0)
1−x(0,1)
1),(x(0,0)
2−x(0,1)
2)));
4Sijointly execute as step 3 over x(1,0)
iandx(1,1)
i;
5Siperforms transpose yi←yi.transpose (2,3,0,1);
6Sireturns yi.
Sijointly calculates the maximum value of all pooling regions
sequentially. Within the particular 2 ×2 pooling region R,t h e
2-D index of the maximum position is initialized to (b1,b2).
S1and S2are not allowed to directly exchange their own
feature values. Euphemistically, Sicalculates the differences
shares λibetween position (b1,b2)and(j,k)(line 4). By trans-
ferring λi,Sido not disclose the speciﬁc feature information,
but can easily determine the relationship between the values
in these two positions. After constantly updating the location
index (b1,b2)of the maximum value, Sican get the max-
imum value shares yR
iof the pooling region R(lines 6–8).
After traversing all pooling regions, Sican securely obtain
the max-pooling feature share yi.
Optimization: Unfortunately, the input is generally a
multidimensional array, and the SecMaxPool protocol does not
effectively avoid the additional overhead associated with mul-
titier loops. In order to take full advantage of the array as a unitof calculating, we design a fast SecMaxPool (Fast-MaxPool)
protocol. As illustrated in Protocol 5, S
iﬁrst splits the input
feature map xiinto four submaps max {xj,k
i,j,k=0,1}accord-
ing to the even and odd superscripts (j,k)(line 2), and then
calculates the difference between the corresponding positions
by array subtraction. Afterward, Sican obtain the compari-
son results between corresponding positions indirectly (lines 3
and 4). Especially, the additional transpose operation is toavoid that the split steps disrupt the original pooling order.
For better understanding, an instance of the Fast-
SecMaxPool protocol is as shown in Fig. 7. It should beemphasized that S
1andS2only know the difference result
(λ1,λ2), but not {x(j,k),j,k=0,1}.Sican judge (x(0,0)
1+
Authorized licensed use limited to: Univ of  Calif San Diego. Downloaded on July 19,2022 at 20:42:05 UTC from IEEE Xplore.  Restrictions apply. 2794 IEEE INTERNET OF THINGS JOURNAL, VOL. 9, NO. 4, FEBRUARY 15, 2022
x(0,0)
2)>( x(0,1)
1−x(0,1)
2)according to λ=λ1+λ2. Speciﬁcally,
such comparisons need to be performed three times.
C. Object Classiﬁcation Results
Upon receiving classiﬁcation shares Oifrom the edge
servers, vehicle V2combines Oito decrypt the information
provided by the two P-CNN models on edge servers.
According to the idea of ASS, simply adding Oiyields the
same classiﬁcation result Oas what the original CNN will
produce by processing the original image I.
D. Feasibility for Multiparty Computation
To better understand the P-CNN framework, only the two-
party setting (i.e., S1andS2) is discussed above. However,
in the CA Vs system, two parties are not enough when one
of the edge servers is ofﬂine or vehicle (CA V) is out of that
coverage.
Thus, in this section, we discuss the executing P-CNN in
multiparty setting (i.e., Si,i∈{1,2,3}). For instance of three-
party setting, each private image Iis randomly split three
shares Ii(I=/summationtext
iIi). Adopting (3,2)secret sharing, each
edge server Sihas two shares of three shares (Ii,Ij),j=
(i+1)mod 3. Suppose S3has some communication problem,
andS1andS2can cooperatively perform P-CNN and recover
I=I/prime
1+I/prime
2[i.e.,(2,2)secret sharing], where S1calculates
I/prime
1=I1+I2andS2calculates I/prime
2=I3. This method can
overcome huge communication overhead caused by real-time
collaboration between multiple servers and can also effectivelysolve the soft handoff between CA V and edge servers in the
CA Vs system. Obviously, this method can also be applied to
n-party ( n≥3) setting. At this point, we adopt (n,2)secret
sharing to randomly split image, while any two servers can
cooperatively perform P-CNN, and n−2 edge servers can
be tolerated to lost connection. In fact, CA V only needs toselect the two closest edge servers to establish a connection
for privacy-preserving object classiﬁcation task.
V. T
HEORETICAL ANALYSIS
A. Complexity Analysis
First, we analyze the computational complexity of key gen-
eration, image encryption, and decryption. The key is a stream
sequence composed of several chaotic sequence values. In
order to encrypt the image with size τ1τ2τ3, the computa-
tional complexity of key generation depends on the image
size, i.e., O(τ1τ2τ3). While the iterative process of encryption
and decryption only contains some modular and exclusive-oroperations, so the computational complexity is also O(τ
1τ2τ3).
Assume that the bit width of the input is l. Since the length of
the key is one-to-one corresponding to the size of the image,
Tonly needs one round of ofﬂine communication and bears
2τ1τ2τ3loverhead for key transmission.
Next, we analyze the computational and communication
complexity of secure protocols proposed in this article. Since
Tcan complete the computation ofﬂine, we can ignore the its
overhead. Assume that the input size for each secure protocol
isn. For secure noninteractive protocols (i.e., SecAdd/SecSub,TABLE I
COMPARISONS OF COMPUTATIONAL COMPLEXITY
TABLE II
COMPARISONS OF COMMUNICATION COMPLEXITY
SecSMul), Sican locally compute without interaction com-
munication. Sionly needs to perform some same-dimensional
linear computation, so the computational complexity of these
protocols is only O(n). As illustrated in the Tables I and II,
the computational complexity of the SecComp protocol is the
same as that of Huang et al. [24], which is related to bit
width l. On the other hand, the communication complexity of
the SecComp protocol is better than Huang, because of the
reduced transmission message size per communication in theSecBitTrans protocol.
Moreover, we analyze the complexity of each layer in
P-CNN. The CONV layer and FC layer only contain addi-tion and scalar multiplication, and S
idoes not need to
interactive with each other using SecAdd and SecSMul pro-
tocol. Compared with the VGG16 network [11], Sidoes not
need to perform additional computational operations, and its
computational complexity is O(e1e2(d1−e1+1)(d2−e2+1)).
The ReLU layer invokes the SecComp protocol to get MSB ofinput, as well as adopting the SecMul protocol [24] to convert
XOR sharing of MSB to additive sharing type. The computa-
tional complexity of the SecReLU protocol is O(ln). Except
for the SecComp protocol, Sineeds two rounds to perform the
SecMul protocol, costing 3 nloverhead in the ReLU layer. In
the MAX-POOL layer, Sineeds to perform three comparisons,
so the communication round is three times than the ReLU
layer. Because the SecMaxPool and Fast-SecMaxPool proto-cols in P-CNN use swap difference instead of the SecComp
protocol, the communication overhead is lower than that of
work [24].
B. Correctness Analysis
Due to the decomposability of linear computation,
SecAdd/SecSub and SecSMul protocols are obviously correct.For the SecBitTrans protocol, we can disassemble the calcu-
lation process as follows. Since that θ
1⊕θ2=μ1⊗μ2,
η1=u1⊕μ1,η2=u2⊕μ2,f1⊕f2=(μ1⊕η1)⊗(μ2⊕η2)=
u1⊗u2can be inferred. In the SecComp protocol, for j=0,
f(0)=u(0);f o r j=1,..., l−1,f(j)
1⊕f(j)
2=(u(j)
1⊕
u(j)
2)⊕(c(j−1)
1⊕c(j−1)
2). Therefore, f(l−1,...,0)
1⊕f(l−1,...,0)
2=
u1+u2. Among this, fl−1=fl−1
1⊕fl−1
2is the MSB of
Authorized licensed use limited to: Univ of  Calif San Diego. Downloaded on July 19,2022 at 20:42:05 UTC from IEEE Xplore.  Restrictions apply. XIONG et al. : TOWARD LIGHTWEIGHT, PRIV ACY-PRESERVING COOPERATIVE OBJECT CLASSIFICATION 2795
input. Note that negative numbers will be calculated in the
corresponding complement form. Therefore, SecBitTrans andSecComp protocols are correct.
In addition, we employ these secure protocols to realize nor-
mal calculation involved in the VGG16 network. The correctanalysis is as follows. After calling the noninteractive proto-
cols, the CONV and FC layers can execute correctly. For the
ReLU layer, the SecComp protocol has proved to be correct.According to the
XOR sharing ζiof MSB, we can obtain the
additive sharing tiof MSB, satisfying t1+t2=ζ1+ζ2+ζ1·ζ2.
The ReLU result y=x·(1−t).I fx≥0, then t=0, 1−t=1,
andy=x;o t h e r w i s e ,( x<0), then t=1, 1−t=0, and
y=0. For the MAX-POOL layer, the core operation is the
three comparisons in SecMaxPool or Fast-SecMaxPool pro-
tocol. λ=(x1(b1,b2)−x1(j,k))+(x2(b1,b2)−x2(j,k))=
x(b1,b2)−x(j,k),i fλ< 0, it means that x(b1,b2)<x(j,k),
and the index (b1,b2)needs to update by (i,j).A f t e rt h e
comparison, the index (b1,b2)belongs to the maximum in
pooling region R. Similarly, Fast-SecMaxPool opens up a
new array space (y1,y2)and iteratively updates the elements
in the array until all values in the pooling region are com-
pared. Speciﬁcally, ((x(0,0)
1−x(0,1)
1)+(x(0,0)
2−x(0,1)
2))=
(x(0,0)−x(0,1)); by comparison, the larger elements of the
two arrays x(0,0)and x(0,1)are stored in (y1,y2). Finally,
(y1,y2)stores the larger values for each of the four arrays
{x(0,0),x(0,1),x(1,0),x(1,1)}. Therefore, the processes of ReLU
and MAX-POOL layers are correct.
Moreover, the calculations involved in the image split and
object decryption are obvious correct, i.e., I=I1+I2andO=
O1+O2. Image encryption and decryption are a set of inverse
operations, for the ﬁrst pixel value of the image Ii,Pi(1)=
Ii(1)⊕δ1(1),Bi(1)=Pi(1), and Ii(1)=Pi(1)⊕δ1(1).
For the remaining pixel values, the ﬁrst round of encryptionP
i(k)=((Ii(k)+δ1(k−1))mod 256 )⊕((δ1(k)+Pi(k−1))mod
256)corresponds to the second round of decryption Ii(k)=
(Pi(k)⊕(Pi(k)+δ1(k−1)mod 256 )−δ1(k−1))mod 256. While
the second round of encryption Bi(k)=(Pi(k))⊕((Bi(k−
1)+δ2(k)mod 256 )⊕δ2(k−1))corresponds to the ﬁrst
round of decryption Pi(k)=(Bi(k))⊕((Bi(k−1)+δ2(k)mod
256)⊕δ2(k−1)). Therefore, these encryption and decryption
processes are correct.
C. Security Analysis
In the HBC model, two servers T,S1, and S2are not collu-
sive. PPT adversary Acan only corrupt and get the view (i.e.,
feature information) of at most one of S1andS2. To better
demonstrate security, we formalize a deﬁnition as follows.
Deﬁnition 1: We say that a protocol is secure if there exists
a probabilistic polynomial-time simulator Mthat can generate
a view View simfor the adversary Ain the real world and the
view is computationally indistinguishable from its real view
View real.
Lemma 1: A protocol is perfectly simulatable if all its
subprotocols are perfectly simulatable [35].
Lemma 2: If a random element ais uniformly distributed
onZnand independent from any variable b∈Zn, then a±b
is also uniformly random and independent from b[36].Since our protocols can be simulated in practice, we need
to learn from above lemmas to assist the proof process.
Theorem 1: The SecAdd/SecSub and SecSMul protocols
are secure in the HBC model.
Proof: For the SecAdd/SecSub protocol, the real view
View realofS1andS2is{u1,v1,f1}and{u2,v2,f2}.T h es i m -
ulator Mcan easily generate the corresponding simulation
view View sim, and View realare computationally indistinguish-
able from View simforA. Similarly, View realofS1andS2in
the SecSMul protocol are {p1,q}and{p2,q}. The input qis
a public value. Therefore, the SecAdd/SecSub and SecSMulprotocols are proved to be secure in the HBC model.
Theorem 2: The SecBitTrans and SecComp protocols are
secure in the HBC model.
Proof: For the SecBitTrans protocol, the inputs ui(i=
1,2)are uniformly random. From the perspective of Si,
View realis{ui,μi,θi,ηi,η3−i,fi}. Since {μi,θi}are random
number ofﬂine generated by T,ηiare also uniformly random
according to Lemma 1. Sicannot infer the real inputs ufrom
ηi+ηi, but obtain the output fi. As a consequence, the real
view View realis simulatable for Mand computationally indis-
tinguishable from the simulated view View simforA. Since the
SecBitTrans protocol can be simulated, the SecComp proto-
col is simulatable according to Lemma 1. View realofSiis
{ui,χi,αi,βi,fi}. Also, the SecBitTrans protocol has proved
to be secure, and {χ1,αi,β1}are uniformly random. Finally,
Sican be obtain the output fi, subjected to f1⊕f2=u1+u2.
Obviously, the MSB fl−1
iis also uniformly random. Mcan
generate simulation view View simofSi, which is computation-
ally indistinguishable from View real. Thus, SecBitTrans and
SecComp protocols are secure in the HBC model.
Theorem 3: The SecReLU, SecMaxPool, and
Fast-SecMaxPool protocols are secure in the HBC model.
Proof: Since the security of the SecComp protocol has
been proved in Theorem 1, the security of the SecMul protocol
has been proved in work [24]. Clearly, {ζi,si,ti,yi}are uni-
formly random. Since SecComp and SecMul protocol can be
simulated, the SecReLU protocol is simulatable by Maccord-
i n gt oL e m m a1 .V i e w simis computationally indistinguishable
from View realofSi. For the SecMaxPool protocol, the inputs xi
are uniformly random. View realofSiis{xi,λ1,λ2,b1,b2,yi}.
Even if Sigets the difference λ3−iandλ(i.e., x(b1,b2)−
x(j,k)), it cannot recover x(j,k). As a result, for A,V i e w real
and View sim, which is generated by M, are computation-
ally indistinguishable. For the Fast-SecMaxPool protocol, theinput is same as the SecMaxPool protocol. View
realofSiis
{x(0,0)
i,x(0,1)
i,x(1,0)
i,x(1,1)
i,yi}. This means that Aneeds to cor-
rupt both S1andS2to recover {x(0,0),x(0,1),x(1,0),x(1,1),y},
however, S1orS2are assumed not to be collusive, so the
Acannot obtain meaningful information. Thus, the SecReLU,
SecMaxPool, and Fast-SecMaxPool protocols are secure in the
HBC model.
Theorem 4: The image reencryption, image decryption,
image process with P-CNN, and object decryption are secure
in the HBC model.
Proof: In the process of image reencryption, a vehicle
V1randomly splits the image Iinto I1andI2and encrypts
them into B1andB2. Then, V1sends the ciphertext image B1
Authorized licensed use limited to: Univ of  Calif San Diego. Downloaded on July 19,2022 at 20:42:05 UTC from IEEE Xplore.  Restrictions apply. 2796 IEEE INTERNET OF THINGS JOURNAL, VOL. 9, NO. 4, FEBRUARY 15, 2022
Fig. 8. Instance of manual KITTI data sets.
andB2toS1andS2, respectively. If the adversary corrupts
S1orS2, obtaining I1orI2cannot restore the original image
I. However, if Ais capable of corrupting the communica-
tion links between V1andS1as well as V1andS2at the
same time, or even directly corrupting V1, then Acan easily
obtain the original image I. This is a very practical security
problem, and the additional encryption scheme described inSection IV-A is designed to avoid such a bad situation. Since
B
1+B2/negationslash=I, even if both B1andB2are obtained, Acannot
obtain any meaningful information, depending on the securityof the encryption scheme. The detailed security experiment is
conducted in Section VI-A. In the process of object decryption,
S
1andS2send the extracting feature O1andO2to the receiver
vehicle V2.V2can secure obtain the classiﬁcation result O
by calculating O1+O2, without leaking any image privacy.
Additionally, P-CNN employs SecAdd, SecSub, and SecSMulprotocols to perform CONV and FC operation, and employs
SecReLU and SecMaxPool (or FastMaxPool) protocols to per-
form ReLU and MAX-POOL operations. The above protocolshave been proved to be secure; thus, the image process with
P-CNN is also secure.
VI. E XPERIMENT AND RESULTS
As our framework is designed for the CA Vs system, we
choose the real-world KITTI data set [37] to train and test our
model. In order to match object classiﬁcation task, we pro-
cess the KITTI data set by cropping out manually the vehiclesand pedestrians from each frames provided in the data set, as
shown in Fig. 8. The customized data set contains 3000 train-
ing samples and 750 test samples, with the size (224,224,3)
of each sample. Similar to the previous privacy-preserving
schemes, in this article, we train the network in plaintext and
inference over encrypted image. All experiments are simulatedon the personal computer of Ubuntu 14.04 with the following
hardware conﬁgurations, Intel Xeon E5-10 GPU with 4-GB
RAM, and 32-GB main RAM, and softwares, deep learningframework CAFFE, Interpreter Python3.5, and IDE PyCharm.
Speciﬁcally, the package Numpy is used as a multidimensional
container of numbers to execute our secure protocol in parallel.
Next, we ﬁrst discuss the actual security of the
image encryption (decryption) described in Section IV-A
(Section IV-B) and analyze it in detail from the aspects
of key sensitivity, pixel correlation, and differential attack.
Then, we evaluate the proposed secure protocols in termsof computational cost and communication overhead, which
directly affects the efﬁciency of P-CNN. In order to fully
show the performance of our framework, we also moni-tor the performance of each network layer in real time and
make a comprehensive comparison with the existing excellent
Fig. 9. Visual effect of original image and encrypted images. (a) Encrypted
image encrypted with keyreal. (b) Original image decrypted with keyreal.( c )
Recover image decrypted with keyﬁct.
literature. Each experiment result is represented by the mean
value of repeated runs of ten times.
A. Security of Image Encryption
1) Key Sensitivity Analysis: In our image encryption
scheme, the encryption key is related to the value of(γ
1(0),γ2(0),γ3(0)); here, we set it to (0.5,0.5,0.5). In gen-
eral, a secure encryption scheme relies heavily on key sensitiv-
ity, using two slightly different keys to decrypt an image, and
the results are quite different. For encrypted images encrypted
with key keyreal=(0.5,0.5,0.5), in order to fully reveal the
sensitivity of the key, we decrypt them with the correct key
keyrealand the ﬁctitious key keyﬁct=(0.5+10−8,0.5,0.5),
respectively. As shown in Fig. 9, the difference between theﬁctitious key key
ﬁctand the correct key keyrealis only 10−8,
but the correct original image cannot be recovered, and any
characteristic information of image cannot be obtained.
In fact, adversary Acan only decrypt the correct image
when the ﬁctitious key keyﬁct=(γ/prime
1(0),γ/prime
2(0),γ/prime
3(0))simul-
taneously satisﬁes |γ/prime
1(0)−γ1(0)|≤10−8,|γ/prime
2(0)−γ2(0)|≤
101, and|γ/prime
3(0)−γ3(0)|≤102. It is extremely difﬁcult for A
to construct a suitable set of keys over a large range of real
numbers. If the unlimited space of the key is [10−10,1010]3,
then the probability that Adecrypts correctly is 10−35, which
is a very low probability. Obviously, our encryption scheme is
sufﬁcient to resist against the exhaustive attacks with existing
computer capabilities.
2) Pixel Correlation Analysis: Pixel correlation is a impor-
tant statistical characteristic measuring image encryptionschemes. The strong correlation between image pixels threat-
ens the security of image information. The lower the correla-
tion, the higher the degree of pixel value confusion. As shownin Fig. 10, the adjacent pixel values in the original image I
have a strong linear relationship. In fact, this means that the
adjacent pixel values have a strong correlation. Given the pixelvalues at a certain location, it is reasonable to infer the adja-
cent pixel values. In contrast, when the image is encrypted,
the correlation between the pixel values at any two locations isalmost identical, which means that the above conjectures are
no longer possible. The relationship between adjacent pixel
values becomes sharp, and the characteristic information ofthe original image is well disturbed.
3) Differential Attack Analysis: Differential attack usually
means that the potential adversary extracts some information
about the key by changing the original image Islightly, or
Authorized licensed use limited to: Univ of  Calif San Diego. Downloaded on July 19,2022 at 20:42:05 UTC from IEEE Xplore.  Restrictions apply. XIONG et al. : TOWARD LIGHTWEIGHT, PRIV ACY-PRESERVING COOPERATIVE OBJECT CLASSIFICATION 2797
Fig. 10. Pixel correlation. (a) Pixel correlation of original image I.( b )P i x e l
correlation of encrypted image B.
TABLE III
COMPARISONS OF NPCR AND UACI
even only one pixel value, and then comparing it with the
encrypted image B. In order to make the difference attack
infeasible, a minor modiﬁcation in Ishould lead to the sub-
stantial difference in B. Generally speaking, the number of
pixel change rate (NPCR) and unit of average change intensity
(UACI) are used to measure the impact of one pixel changeinIonB. The larger NPCR and NPCR are, the higher the
degree of pixel confusion is. Suppose that I(k)andB(k)be
thekth pixel of IandB, and NPCR and UACI are deﬁned in
NPCR =/summationtext
(τ1,τ2,τ3)
k=1I(k)
τ1×τ2×τ3×100% (8)
I(k)=/braceleftbigg0,ifI(k)=B(k)
1,ifI(k)/negationslash=B(k)(9)
UACI =/summationtext(τ1,τ2,τ3)
k=1|I(k)−B(k)|/255
τ1×τ2×τ3×100%.(10)
As shown in Table III, the NPCR of these schemes has lit-
tle difference. In the other hand, compared with the image
encryption method based on lookup tables [38] and that based
on single Fibonacci chaotic mapping [39], P-CNN using the
fusion of three chaotic sequences has a greater intensity of
disrupting image pixels (i.e., UACI). After two rounds ofencryption calculation, the UACI of P-CNN is as high as
33.49%. Obviously, P-CNN can resist differential attack better
than these schemes [38] and [39].
B. Performance of Proposed Secure Protocols
These secure computing protocols are designed to securely
implement P-CNN, and the main factors affecting their
performance include: parallel batch size and bit-width lof
inputs. From Fig. 11(a) and (b), the runtime of the SecBitTrans
and SecComp protocols increases with the parallel batch size.
Even if 10
5inputs are processed in parallel, the running time
of the SecBitTrans and SecComp protocols can be controlled
within 4 and 16 ms, respectively. Compared with the SecCmpTABLE IV
COMPARISON OF RUNTIME FOR KEYGENERATION ,IMAGE
ENCRYPTION ,AND DECRYPTION
protocol proposed in [24], the efﬁciency of our SecComp pro-
tocol becomes more clear with the increase of batch size.This is because that we use two-tuples operator to realize
the conversion from additive sharing to
XOR sharing, rather
than the Beaver triple operator, thus saving about 1 /3o ft h e
cost. SecReLU protocol can securely and correctly obtain the
output of ReLU function by using SecComp and SecMulprotocols. From Fig. 11(c), the runtime of the SecReLU pro-
tocol increases with the parallel batch size, slightly higher
than the original ReLU function, but better than work [24].Additionally, SecMaxPool protocol adopts the Naive method
of swap difference instead of using SecComp protocol in
MAX-POOL layer, reducing computational cost, as shown inFig. 11(d). Furthermore, Fast-SecMaxPool protocol enhances
the parallelization efﬁciency on the basis of SecMaxPool pro-
tocol, and achieves a slightly higher computational cost thanthe original MAX-POOL function.
From Fig. 11(e) and (f), the communication overhead of
SecBitTrans and SecComp protocol increases with the bitwidth lof inputs. Compared with the SecCmp protocol
proposed in [24], our SecComp protocol can reduce about 2 /3
of the communication overhead. From Fig. 11(g) and (h), thecommunication overhead of SecReLU and SecMaxPool/Fast-
SecMaxPool protocols increases with the bit width lof inputs.
Importantly, these protocols proposed in this article are better
than work [24] in the aspect of communication overhead.
Moreover, the computational error of SecComp protocol
is negligible. Since the fractional portion of the ﬁxed-point
number is converted to the integer domain for computation,
SecComp Protocol can accurately determine the relationshipbetween the input and 0. Therefore, SecReLU protocol has no
computational error using the SecComp protocol. Additionally,
since no approximate calculation is involved in CONV , POOL,and FC layers, their error is always maintained at 0.
C. Performance of Object Classiﬁcation Framework
In the encryption phase, the sender vehicle V
1needs to ran-
domly split the original image Iinto two images I1andI2,
and then encrypts them to obtain the ciphertext image B1and
B2. After receiving the ciphertext image, the two servers S1
andS2decrypt them independently. As shown in Table IV,
0.686 s is required for V1to encrypt one image, and 0.655 s
is required for S1andS2to decrypt one image. Note that S1
andS2are executed independently and in parallel, so it takes
only time to decrypt one image. The comparison result shownthat our encryption efﬁciency is higher than that of [39]. The
ﬁrst schemes [40] seem to be more efﬁcient at encrypting and
decrypting, but generating keys takes a signiﬁcant amount oftime, i.e., 12.0 s, which is not allowed in a dynamic commu-
nication environment. In contrast, only 0.168 s is required in
Authorized licensed use limited to: Univ of  Calif San Diego. Downloaded on July 19,2022 at 20:42:05 UTC from IEEE Xplore.  Restrictions apply. 2798 IEEE INTERNET OF THINGS JOURNAL, VOL. 9, NO. 4, FEBRUARY 15, 2022
Fig. 11. Efﬁciency and effectiveness of the proposed secure computing protocols. (a) Runtime of SecBitTrans protocol varies from batch size. (b) Run time
of SecComp protocol varies from batch size. (c) Runtime of SecReLU protocol varies from batch size. (d) Runtime of Fast-SecMaxPool protocols varies
from batch size. (e) Communication overhead of SecBitTrans protocol varies from bit width. (f) Communication overhead of SecComp protocol varies fr om
bit width. (g) Communication overhead of SecReLU protocol varies from bit width. (h) Communication overhead of Fast-SecMaxPool protocol varies fro m
bit-width.
TABLE V
COMPARISON OF THE COMMUNICATION OVERHEAD IN ENCRYPTION
AND DECRYPTION PHASES FOR A BATCH OF 750 I MAGES
FROM THE KITTI [37]
our encryption scheme, which means that the keys used for
encryption can be updated at any time for greater security.Additionally, receiver vehicle V
2requires only the addition of
the two outputs O1andO2in the decryption phase, consuming
only 0.03 s.
On the other hand, the communication overhead in encryp-
tion and decryption phases are 143.55 and 5.859 MB, as shown
in Table V. The images consist of 224 ×224 pixels, and
each pixel is stored as 4 bytes. Using HE scheme, each pixel
is encrypted as ﬁve polynomials, and each coefﬁcient in the
polynomial requires 24 bytes. Our communication overhead isfar less than CryptoNets [20].
Moreover, we evaluate the computational efﬁciency of each
layers in P-CNN, and compare with the previous work, as
shown in Tables VI and VII. CryptoNets [20], CryptoDL [21],
and Gazelle [22] mainly use HE to realize the calculation in theneural network, and FALCON [41] combines the fast fourier
transform (FFT). Obviously, our runtime in CONV and FC
layers is far less than CryptoNets [20], CryptoDL [21], andGazelle [22]. Also, our scheme can deal with feature map of
larger size (i.e., 224 ×224×64 in CONV layer and 800 inTABLE VI
COMPARISON OF THE RUNTIME FOR CONV AND FC
TABLE VII
COMPARISON OF THE RUNTIME FOR RELU AND MAX-POOL
FC layer) than scheme FALCON [41]. In the same amount of
time, although the work [24] also applies the idea of ASS, the
computational complexity of comparison calculation involved
in our SecReLU protocol is much less. For the MAX-POOLlayer, the work [24] uses the proposed comparison function
several times to determine the maximum value in the pool-
ing region, while P-CNN directly ﬁnds the maximum valuethrough the difference between the two pairs. Obviously, the
cost of this calculation method is very small.
Authorized licensed use limited to: Univ of  Calif San Diego. Downloaded on July 19,2022 at 20:42:05 UTC from IEEE Xplore.  Restrictions apply. XIONG et al. : TOWARD LIGHTWEIGHT, PRIV ACY-PRESERVING COOPERATIVE OBJECT CLASSIFICATION 2799
TABLE VIII
COMPARISON OF THE PERFORMANCE FOR DIFFERENT
PRIV ACY -PRESERVING SCHEME
TABLE IX
COMPARISON OF THE PERFORMANCE FOR P-CNN AND
ORIGINAL VGG16 M ODEL
Privacy-preserving network adopts the designed secure layer
protocols to perform privacy computing over encrypted image.
In order to facilitate comparison, we specially execute thesmaller CNN network, consisting of two CONV layers, three
ACT layers, two MAX-POOL layers, and two FC layers.
The performance comparison results of different schemes are
shown in Table VIII. Obviously, running the same network,
P-CNN consumes less computing cost and communicationoverhead than the previous work. Furthermore, we utilize more
complex VGG16 [43] model to implement P-CNN. As shown
in Table IX, P-CNN can achieve the same classiﬁcation accu-racy as the original VGG16 model. The computational cost of
P-CNN is 10 .26×times than the VGG16 model, with an addi-
tional communication overhead of 327.78 MB. Synthetically,P-CNN has great advantages in computing and communica-
tion efﬁciency, and it is more realistic to execute in the edge
server.
VII. R
ELATED WORK
Most of the existing image encryption schemes are based
on symmetric encryption [38] or chaos theory [27], [28]. The
symmetric encryption over image involves complicated byteor bit displacement, and the construction principle of S-box
cannot be explained in detail. Generating keys and encryption
usually leads to a large amount of overhead, which is notsuitable for real-time environment such as CA V .
In contrast, the image encryption based on the chaos theory
has higher encryption efﬁciency, and the generated cipher-text image has good randomicity in pixel value distribution.
Run-He et al. [44] proposed a color image encryption algo-
rithm based on the mixed diffusion mechanism and chaos,which extends the 2-D logical map to the 4-D chaotic
map to replace the image pixel value. However, there is
a certain degree of distortion in the decrypted recovered
image. Kaur et al. [40] proposed a color image encryption
(TFCM) using nondominated sorting genetic algorithm-based5-D chaotic map, which decomposed the input color image
into three channels, and obtained the ﬁnal encrypted image
through dual-tree complex wavelet transform. The experimentsshow that the TFCM scheme can resist against exhaustive
and differential attacks, but the time to generate the key isslow. Hu et al. [39] proposed a color image encryption algo-
rithm based on Fibonacci chaotic system, which scramblesthe image pixel by using the chaotic sequence, and performs
mutual exclusion-or operation on adjacent pixel values to
further reduce the pixels correlation.
On the task of privacy-preserving image classiﬁcation, the
existing research work has made a breakthrough to some
extent. CryptoNets [20] is the ﬁrst privacy-preserving neu-ral network model using leveled HE (LHE). However, it only
supports simple secure linear operations, such as the acti-
vation layer using the square function, which is now rarelyused in network training and prediction. Therefore, some
polynomial functions [21] are designed to reproduce the com-
monly used activation functions, such as ReLU, Sigmoid,
and Hyperbolic tangent (Tanh). SecureML [45] proposed the
ﬁrst privacy-preserving protocol for training multiple machinelearning models between two noncollusive servers, which
uses piecewise linear function to replace activation func-
tion. MiniONN [42] transformed a neural network modelinto an oblivious version, and adopts lattice-based AHE to
generate multiplication triplets. Meanwhile, this scheme puts
some computation ofﬂine, and greatly improves the calculationefﬁciency.
Gazelle [22] used a judicious combination of packed AHE
(PAHE) and garbled circuit-based secure two-party computa-tion, vectorizing the designed protocol, and further improving
framework efﬁciency to some extent. Falcon [41] developed
fast and secure protocols for convolutional and fully connectedlayers-based FFT, which is a special solution with higher com-
putational efﬁciency than the secure protocol based on HE.
Huang et al. [24] proposed a new solution based on addition
secret sharing, and designed a SecComp function to force two
noncolluding edge servers to perform the activation layer andpooling layer. The experimental results show that the compu-
tational cost and communication overhead of our solution are
much lower than that of the models based on HE. Furthermore,Maet al. [46], [47] implemented privacy-preserving speech
recognition and face recognition using SComp protocols in
work [24], and Liu et al. [48] proposed a secure object detec-
tion model with image and feature privacy protection. The
optimization of the SComp protocol is meaningful for these
models applying privacy-preserving tasks.
Based on the existing work, this article speciﬁcally designs
a chaotic mapping-based image encryption scheme to avoid
channel privacy leakage. In addition, we design a lightweightand secure computing protocol based on ASS technology,
instead of using HE and garbled circuit with high compu-
tational cost.
VIII. C
ONCLUSION
Focusing on object classiﬁcation problem, we proposed a
lightweight, privacy-preserving cooperative object classiﬁca-
tion framework for CA V . The key innovation of the framework
is the introduction of the P-CNN model, which processesencrypted images shared from vehicles and produces mean-
ingful classiﬁcation results when combined. The additional
Authorized licensed use limited to: Univ of  Calif San Diego. Downloaded on July 19,2022 at 20:42:05 UTC from IEEE Xplore.  Restrictions apply. 2800 IEEE INTERNET OF THINGS JOURNAL, VOL. 9, NO. 4, FEBRUARY 15, 2022
image obfuscation is to ensure the security of the image dur-
ing storage and transmission. In P-CNN, the operations inthe original CNN model (VGG16) are implemented by our
secure protocols, based on the ASS technique. The experi-
mental results demonstrate that P-CNN offers exactly the sameclassiﬁcation results as the VGG16 model, without requiring
vehicles to send original image data directly, which may con-
tain privacy information. Moreover, the computational cost andcommunication overhead on two edge servers are acceptable.
In future work, we expect to design an adaptive addition
cycle mechanism to further reduce the runtime involved inSecComp calculation. Additionally, we need to construct a
secure detection paradigm combined with ASS, which can be
applied to range positioning [49], 2-D-object detection [50],
3-D-object detection [51], etc. Potentially, we need to extend
ASS to three or more parties for processing to achieve a higherlevel of security for CA Vs.
R
EFERENCES
[1] J. Van Brummelen, M. O’Brien, D. Gruyer, and H. Najjaran,
“Autonomous vehicle perception: The technology of today and tomor-
row,” Transp. Res. C, Emerg. Technol. , vol. 89, pp. 384–406, Apr. 2018.
[2] L. Hu, Y . Qian, J. Chen, X. Shi, J. Zhang, and S. Mao, “Photo
crowdsourcing based privacy-protected healthcare,” IEEE Trans. Sustain.
Comput. , vol. 4, no. 2, pp. 168–177, Apr.–Jun. 2019.
[3] Q. Yang, A. Lim, S. Li, J. Fang, and P. Agrawal, “ACAR: Adaptive con-
nectivity aware routing for vehicular ad hoc networks in city scenarios,”Mobile Netw. Appl. , vol. 15, no. 1, pp. 36–60, 2010.
[4] Q. Chen, S. Tang, Q. Yang, and S. Fu, “Cooper: Cooperative perception
for connected autonomous vehicles based on 3D point clouds,” in Proc.
39th IEEE Int. Conf. Distrib. Comput. Syst. (ICDCS) , Dallas, TX, USA,
2019, pp. 514–524.
[5] Q. Chen, X. Ma, S. Tang, J. Guo, Q. Yang, and S. Fu, “F-Cooper: Feature
based cooperative perception for autonomous vehicle edge computingsystem using 3D point,” in Proc. 4th ACM/IEEE Symp. Edge Comput.
(SEC) , 2019, pp. 88–100.
[6] Q. Liu, “An improved approach to exposing JPEG seam carving under
recompression,” IEEE Trans. Circuits Syst. Video Technol. , vol. 29, no. 7,
pp. 1907–1918, Jul. 2019.
[7] Y . Lu, X. Huang, K. Zhang, S. Maharjan, and Y . Zhang,
“Communication-efﬁcient federated learning and permissioned
blockchain for digital twin edge networks,” IEEE Internet Things J. ,
vol. 8, no. 4, pp. 2276–2288, Feb. 2021.
[8] J. Ni, X. Lin, and X. Shen, “Toward privacy-preserving valet parking
in autonomous driving era,” IEEE Trans. Veh. Technol. , vol. 68, no. 3,
pp. 2893–2905, Mar. 2019.
[9] D. Glancy, “Privacy in autonomous vehicles,” Santa Clara Law Rev. ,
vol. 52, no. 4, pp. 1171–1239, 2012.
[10] Q. Jiang, J. Ni, J. Ma, L. Yang, and X. Shen, “Integrated authentication
and key agreement framework for vehicular cloud computing,” IEEE
Netw. , vol. 32, no. 3, pp. 28–35, May/Jun. 2018.
[11] A. Krizhevsky, I. Sutskever, and G. Hinton, “ImageNet classiﬁca-
tion with deep convolutional neural networks,” in Advances in Neural
Information Processing Systems . Red Hook, NY , USA: Curran, 2012,
pp. 1097–1105.
[12] S. Liu, L. Liu, J. Tang, B. Yu, Y . Wang, and W. Shi, “Edge comput-
ing for autonomous driving: Opportunities and challenges,” Proc. IEEE ,
vol. 107, no. 8, pp. 1697–1716, Aug. 2019.
[13] Y . Liu, S. Xie, and Y . Zhang, “Cooperative ofﬂoading and resource
management for UA V-enabled mobile edge computing in power IoTsystem,” IEEE Trans. Veh. Technol. , vol. 69, no. 10, pp. 12229–12239,
Oct. 2020.
[14] J. Ni, K. Zhang, and A. V . Vasilakos, “Security and privacy for mobile
edge caching: Challenges and solutions,” IEEE Wireless Commun. , early
access, Dec. 21, 2020, doi: 10.1109/MWC.001.2000329 .
[15] W. Shi, J. Cao, Q. Zhang, Y . Li, and L. Xu, “Edge computing: Vision
and challenges,” IEEE Internet Things J. , vol. 3, no. 5, pp. 637–646,
Oct. 2016.
[16] B. Yang, D. Wu, and R. Wang, “CUE: An intelligent edge computing
framework,” IEEE Netw. , vol. 33, no. 3, pp. 18–25, May/Jun. 2019.[17] M. Chen, Y . Qian, J. Chen, K. Hwang, S. Mao, and L. Hu, “Privacy
protection and intrusion avoidance for cloudlet-based medical datasharing,” IEEE Trans. Cloud Comput. , vol. 8, no. 4, pp. 1274–1283,
Oct./Dec. 2020.
[18] R. Lu, X. Lin, H. Zhu, P.-H. Ho, and X. Shen, “ECPP: Efﬁcient
conditional privacy preservation protocol for secure vehicular commu-nications,” in Proc. IEEE INFOCOM 27th Conf. Comput. Commun. ,
Phoenix, AZ, USA, 2008, pp. 1229–1237.
[19] B. Jin, D. Jiang, J. Xiong, L. Chen, and Q. Li, “D2D data privacy pro-
tection mechanism based on reliability and homomorphic encryption,”IEEE Access , vol. 6, pp. 51140–51150, 2018.
[20] P. Xie, M. Bilenko, T. Finley, R. Gilad-Bachrach, K. Lauter, and
M. Naehrig, “Crypto-nets: Neural networks over encrypted data,” 2014.[Online]. Available: arXiv:1412.6181.
[21] E. Hesamifard, H. Takabi, and M. Ghasemi, “CryptoDL: Deep
neural networks over encrypted data,” 2017. [Online]. Available:
arXiv:1711.05189.
[22] C. Juvekar, V . Vaikuntanathan, and A. Chandrakasan, “GAZELLE: A
low latency framework for secure neural network inference,” in Proc.
27th USENIX Security Symp. (USENIX Security) , 2018, pp. 1651–1669.
[23] J. Xiong, R. Bi, M. Zhao, J. Guo, and Q. Yang, “Edge-assisted privacy-
preserving raw data sharing framework for connected autonomousvehicles,” IEEE Wireless Commun. , vol. 27, no. 3, pp. 24–30, Jun. 2020.
[24] K. Huang, X. Liu, S. Fu, D. Guo, and M. Xu, “A lightweight privacy-
preserving CNN feature extraction framework for mobile sensing,” IEEE
Trans. Dependable Secure Comput. , vol. 18, no. 3, pp. 1441–1455,
May/Jun. 2021.
[25] C. Luo, J. Ji, Q. Wang, X. Chen, and P. Li, “Channel state information
prediction for 5G wireless communications: A deep learning approach,”IEEE Trans. Netw. Sci. Eng. , vol. 7, no. 1, pp. 227–236, Jan.–Mar. 2020.
[26] E. Ott, C. Grebogi, and J. A. Yorke, “Controlling chaos,” Phys. Rev.
Lett., vol. 64, no. 11, p. 1196, 1990.
[27] N. K. Pareek, V . Patidar, and K. K. Sud, “Image encryption using chaotic
logistic map,” Image Vis. Comput. , vol. 24, no. 9, pp. 926–934, 2006.
[28] K. Mischaikow and M. Mrozek, “Chaos in the lorenz equations: A com-
puter assisted proof,” Bull. Amer. Math. Soc. , vol. 32, no. 1, pp. 66–72,
1995.
[29] A. Shamir, “How to share a secret,” Commun. ACM , vol. 22, no. 11,
pp. 612–613, 1979.
[30] I. Damgård, M. Fitzi, E. Kiltz, J. B. Nielsen, and T. Toft,
“Unconditionally secure constant-rounds multi-party computation forequality, comparison, bits and exponentiation,” in Proc. Theory Cryptogr.
Conf. , 2006, pp. 285–304.
[31] Z. Qin, J. Yan, K. Ren, C. W. Chen, and C. Wang, “Towards efﬁ-
cient privacy-preserving image feature extraction in cloud computing,”inProc. 22nd ACM Int. Conf. Multimedia , 2014, pp. 497–506.
[32] T. Araki, J. Furukawa, Y . Lindell, A. Nof, and K. Ohara, “High-
throughput semi-honest secure three-party computation with an honestmajority,” in Proc. ACM SIGSAC Conf. Comput. Commun. Security ,
2016, pp. 805–817.
[33] J. Wang, S. Hu, Q. Wang, and Y . Ma, “Privacy-preserving outsourced
feature extractions in the cloud: A survey,” IEEE Netw. , vol. 31, no. 5,
pp. 36–41, Sep./Oct. 2017.
[34] D. Beaver, “Efﬁcient multiparty protocols using circuit randomization,”
inProc. Annu. Int. Cryptol. Conf. , 1991, pp. 420–432.
[35] D. Bogdanov, S. Laur, and J. Willemson, “Sharemind: A framework for
fast privacy-preserving computations,” in Proc. Eur. Symp. Res. Comput.
Security , 2008, pp. 192–206.
[36] D. Bogdanov, M. Niitsoo, T. Toft, and J. Willemson, “High-performance
secure multi-party computation for data mining applications,” Int. J. Inf.
Security , vol. 11, no. 6, pp. 403–418, 2012.
[37] A. Geiger, P. Lenz, C. Stiller, and R. Urtasun, “Vision meets robotics:
The KITTI dataset,” Int. J. Robot. Res. , vol. 32, no. 11, pp. 1231–1237,
2013.
[38] J.-X. Chen, Z.-L. Zhu, C. Fu, L.-B. Zhang, and Y . Zhang, “An efﬁ-
cient image encryption scheme using lookup table-based confusion and
diffusion,” Nonlinear Dyn. , vol. 81, no. 3, pp. 1151–1166, 2015.
[39] X. Hu, L. Wei, W. Chen, Q. Chen, and Y . Guo, “Color image encryp-
tion algorithm based on dynamic chaos and matrix convolution,” IEEE
Access , vol. 8, pp. 12452–12466, 2020.
[40] M. Kaur, D. Singh, K. Sun, and U. Rawat, “Color image encryp-
tion using non-dominated sorting genetic algorithm with local chaotic
search based 5 Dchaotic map,” Future Gener. Comput. Syst. , vol. 107,
pp. 333–350, Jun. 2020.
[41] S. Li et al. , “FALCON: A fourier transform based approach for fast
and secure convolutional neural network predictions,” 2018. [Online].
Available: arXiv:1811.08257.
Authorized licensed use limited to: Univ of  Calif San Diego. Downloaded on July 19,2022 at 20:42:05 UTC from IEEE Xplore.  Restrictions apply. XIONG et al. : TOWARD LIGHTWEIGHT, PRIV ACY-PRESERVING COOPERATIVE OBJECT CLASSIFICATION 2801
[42] J. Liu, M. Juuti, Y . Lu, and N. Asokan, “Oblivious neural network
predictions via MiniONN transformations,” in Proc. ACM SIGSAC Conf.
Comput. Commun. Security , 2017, pp. 619–631.
[43] K. Simonyan and A. Zisserman, “Very deep convolutional networks
for large-scale image recognition,” 2015. [Online]. Available:
arXiv:1409.1556.
[44] Q. Run-He, C. Yun, and F. Yu-Zhen, “Integrated confusion-diffusion
mechanisms for chaos based image encryption,” in Proc. 4th Int. Congr.
Image Signal Process. , vol. 2. Shanghai, China, 2011, pp. 629–632.
[45] P. Mohassel and Y . Zhang, “SecureML: A system for scalable privacy-
preserving machine learning,” in Proc. IEEE Symp. Security Privacy
(SP), San Jose, CA, USA, 2017, pp. 19–38.
[46] Z. Ma, Y . Liu, X. Liu, J. Ma, and F. Li, “Privacy-preserving outsourced
speech recognition for smart IoT devices,” IEEE Internet Things J. ,
vol. 6, no. 5, pp. 8406–8420, Oct. 2019.
[47] Z. Ma, Y . Liu, X. Liu, J. Ma, and K. Ren, “Lightweight privacy-
preserving ensemble classiﬁcation for face recognition,” IEEE Internet
Things J. , vol. 6, no. 3, pp. 5778–5790, Jun. 2019.
[48] Y . Liu, Z. Ma, X. Liu, S. Ma, and K. Ren, “Privacy-preserving
object detection for medical images with faster R-CNN,” IEEE
Trans. Inf. Forensics Security , early access, Oct. 10, 2019,
doi: 10.1109/TIFS.2019.2946476 .
[49] S. Ren, K. He, R. Girshick, and J. Sun, “Faster R-CNN: Towards real-
time object detection with region proposal networks,” in Advances in
Neural Information Processing Systems . Red Hook, NY , USA: Curran,
2015, pp. 91–99.
[50] J. Xiong, R. Bi, Q. Chen, and X. Liu, “Towards edge-collaborative,
lightweight and secure region proposal network,” J. Commun. , vol. 41,
no. 10, pp. 188–201, 2020.
[51] X. Chen, H. Ma, J. Wan, B. Li, and T. Xia, “Multi-view 3D object detec-
tion network for autonomous driving,” in Proc. IEEE Conf. Comput. Vis.
Pattern Recognit. , Honolulu, HI, USA, 2017, pp. 1907–1915.
Jinbo Xiong (Member, IEEE) received the Ph.D.
degree in computer system architecture from Xidian
University, Xi’an, China, in 2013.
He was a Visiting Scholar with the Department
of Computer Science and Engineering, University
of North Texas, Denton, TX, USA. He is cur-rently a Full Professor and the Ph.D. supervi-sor with the Fujian Provincial Key Laboratory of
Network Security and Cryptology and the College
of Computer and Cyber Security, Fujian NormalUniversity, Fuzhou, China. He has published more
than 100 publications, containing four ESI highly cited papers and two mono-
graphs and holds more than ten patents in these ﬁelds. His research interests
include secure deep learning, data security, privacy protection, and Internet ofThings.
Prof. Xiong serves as the TPC Chair of the 14th EAI Mobimedia and a
PC member of numerous international conferences. He served or is serving
as a Lead Guest Editor and/or a Guest Editor for several technical journals,such as Security and Communication Networks ,Wireless Communications and
Mobile Computing ,Concurrency and Computation: Practice and Experience ,
andMobile Network and Applications .
Renwan Bi received the M.S. degree in soft-
ware engineering from the College of Mathematics
and Informatics, Fujian Normal University, Fuzhou,
China, in 2021, where he is currently pursuing thePh.D. degree in cyberspace security with the Collegeof Computer and Cyber Security.
His research interests include connected and
autonomous vehicle, deep neural network, securemultiparty computation, and cryptography security.
Youliang Tian (Member, IEEE) received the Ph.D.
degree in cryptography from Xidian University,Xi’an, China, in 2012.
He is a Full Professor and the Ph.D. supervi-
sor with the State Key Laboratory of Public Big
Data and the College of Computer Science andTechnology, Guizhou University, Guiyang, China.He is a Young Changjiang Scholar of the Ministry
of Education. He has authored over 100 publications
and two books. His current research interests includealgorithmic game theory, cryptography and security
protocols, big data security and privacy protection, blockchain, and electronic
currency.
Ximeng Liu (Senior Member, IEEE) received
the B.Sc. degree in electronic engineering andthe Ph.D. degree in cryptography from Xidian
University, China, in 2010 and 2015, respec-
tively.
He is currently a Full Professor and the Ph.D.
supervisor with the College of Mathematics and
Computer Science, Fuzhou University, Fuzhou,
China. He was a Research Fellow with the Schoolof Information System, Singapore ManagementUniversity, Singapore. He has published more than
250 papers on the topics of cloud security and big data security, including
papers in IEEE T
RANSACTIONS ON COMPUTERS , IEEE T RANSACTIONS
ONINFORMATION FORENSICS AND SECURITY , IEEE T RANSACTIONS ON
DEPENDABLE AND SECURE COMPUTING , IEEE T RANSACTIONS
ONPARALLEL AND DISTRIBUTED SYSTEMS , IEEE T RANSACTIONS ON
KNOWLEDGE AND DATA ENGINEERING , IEEE I NTERNET OF THINGS
JOURNAL , and so on. His research interests include cloud security, applied
cryptography, and big data security.
Prof. Liu Awards the Minjiang Scholars Distinguished Professor, the
Qishan Scholars in Fuzhou University, and the ACM SIGSAC China RisingStar Award in 2018.
Dapeng Wu (Senior Member, IEEE) received the
M.S. degree in communication and information
system from Chongqing University of Posts and
Telecommunications, Chongqing, China, in 2006,and the Ph.D. degree in communication and
information system from Beijing University of Posts
and Telecommunications, Beijing, China, in 2009.
He is currently a Full Professor and the Ph.D.
supervisor with the Chongqing University of Posts
and Telecommunications. He has authored over 100
publications and two books. He is the inventor and
co-inventor of 28 patents and patent applications. His current research interestsinclude social computing, wireless networks, and big data.
Prof. Wu serves as the TPC Chair of the 10th Mobimedia and a PC member
of numerous international conferences and workshops. He served or is serv-ing as an Editor and/or a Guest Editor for several technical journals, such asDigital Communications and Networks (Elsevier) and ACM/Springer Mobile
Network and Applications .
Authorized licensed use limited to: Univ of  Calif San Diego. Downloaded on July 19,2022 at 20:42:05 UTC from IEEE Xplore.  Restrictions apply. 