CASE STUDY
AUTONOMOUS VEHICLES
This is part of a set of materials developed by an interdisciplinary 
research team at Stanford University, led by Hilary Cohen,  
Rob Reich, Mehran Sahami, and Jeremy Weinstein. Their original use is 
for an undergraduate course on ethics, public policy, and technology, 
and they have been designed to prompt discussion about issues at the 
intersection of those fields. This case was written by Mark Harris. 2   |   Ethics, Technology, and Public Policy – Autonomous VehiclesIntroduction: Safe at any speed?
Humans are often irresponsible drivers. While in sole control of large metal objects capable of 
travelling at over 100 miles per hour, we routinely eat meals, chat with other people, send text 
messages, and fall asleep. We drive while impaired by drinks, drugs or failing eyesight. We get 
impatient, angry and even murderous behind the wheel, and we have shockingly bad judgement.
On a Friday morning in January 2015, 193 vehicles, including 76 semi-trucks, were involved in a 
single pile-up on a snowy Michigan interstate.1 That is not even the worst multi-vehicle crash in 
history, which dubious honor probably goes to a 300-vehicle wreck in Brazil in 2011.
Human error plays a role in about 90 percent of motor vehicle crashes,2 which kill around 1.25 
million people around the world each year.3 In the US, collisions cause around 37,000 deaths  and an 
estimated $836 billion in total costs annually.4 After years of decline, fatalities are on the rise again, 
possibly due to an increase in distracted driving with digital devices.5
Over the past half century, adoption of safety technologies such as crumple zones, air bags, child car 
seats and energy-absorbing steering wheels have avoided many additional deaths. Seat belts alone 
probably save around 15,000 lives in the US each year.6
In recent years, automated technologies like lane keeping assist and forward collision warning have 
been added to the mix. Because these technologies, ideally, prevent collisions rather than merely 
mitigating their effects, assessing their effectiveness can be tricky. However, research by the National 
Highway Traffic Safety Administration (NHTSA) suggests electronic stability control saves around 
1,300 American lives annually. 
But in the last decade, a suite of new technologies have been developed that some think may 
eliminate – or at least dramatically reduce -- road deaths altogether. In 2011, Sebastian Thrun, a 
Stanford professor and head of Google’s self-driving car program, wrote: “I envision a future in which 
our technology is available to everyone, in every car. I envision a future without traffic accidents or 
congestion.”7
Self-driving cars or autonomous vehicles (A Vs) use sensors, computers and robotic actuators to 
automate some or all driving tasks. In a fully automated future,  the only role for human passengers 
might be to select their final destination, and road deaths could become as rare as aviation disasters.
While reducing or eliminating road deaths remains a rallying call, the reality is that almost no one 
has been developing A Vs with a primary goal of ensuring the safety of drivers, let alone the hundreds 
of thousands of pedestrians, cyclists and other road users also killed by vehicles every year.8 A 
Pentagon project called the DARPA Grand Challenge that kickstarted A Vs in the early 2000s was 
1 Julie Mack, “Michigan I-94’s horrific crash, closure and cleanup by the numbers” , MLive, January 16 2015, https://www.mlive.com/
news/kalamazoo/index.ssf/2015/01/i-94s_horrific_crash_closure_a.html
2 Bryant Walker Smith, “Human Error As A Cause of Vehicle Crashes, ” The Center for Internet and Society, December 18 2013, http://
cyberlaw.stanford.edu/blog/2013/12/human-error-cause-vehicle-crashes
3 Road Traffic Deaths, World Health Organization, https://www.who.int/gho/road_safety/mortality/en/
4 NHTSA, “US Road Crash Data Quick Facts 2016, ” available at https://crashstats.nhtsa.dot.gov/Api/Public/Publication/812451
5 NHTSA, ”Distracted Driving, ” https://www.nhtsa.gov/risky-driving/distracted-driving
6 Charles J Kahane, “Lives Saved by Vehicle Safety Technologies and Associated Federal Motor Vehicle Safety Standards, 1960 to 2012, ” 
NHTSA, January 2015, available at https://www-esv.nhtsa.dot.gov/proceedings/24/files/24ESV-000291.PDF
7 Sebastian Thrun, “Self-Driving Cars Can Save Lives, and Parking Spaces, ” New Y ork Times, December 5 2011, https://www.nytimes.
com/2011/12/06/science/sebastian-thrun-self-driving-cars-can-save-lives-and-parking-spaces.html
8 Distribution of road traffic deaths by type of road user, World Health Organization, available at https://www.who.int/gho/road_safety/
mortality/traffic_deaths_distribution/en/ Ethics, Technology, and Public Policy – Autonomous Vehicles  |   3This work is licensed under a Creative Commons Attribution 4.0 International License.intended to develop military vehicles. Programs from Uber and Google (now spun out as Waymo) 
are focused on providing mobility as a service (MAAS) to replace professional taxi and truck drivers. 
Tesla’s Autopilot, and similar advanced driver assistance systems (ADAS) being rolled out by other 
auto makers, are largely marketed as convenience features. 
Only Toyota’s Guardian system9 stands out as being solely designed to avoid collisions. Although not 
yet commercialized, it will play no role in everyday driving but will simply observe the driver and the 
road conditions, and only step in when necessary to prevent a crash. 
As with many new technologies, there exists a gap between how companies talk about A Vs and what 
they have actually delivered. Far from eliminating all collisions, the relatively few A Vs driving on 
public roads get into minor crashes almost daily.10 While many of these have been blamed on human 
road users, it is not clear how many crashes result from the complexities and social ambiguities 
inherent in our current road systems. Automated driving technologies have also already been 
implicated in several deaths. In fact, the AI Now Institute at New York University, an interdisciplinary 
research institute dedicated to understanding the social implications of AI technologies, says that 
“autonomous vehicles arguably present AI’s most straightforward non-military dangers to human 
safety.”11
How these technologies are developed and regulated, their legal status and the extent to which 
they disrupt current businesses and existing modes of transportation will determine whether they 
deliver all the benefits their evangelists envision, or the ills their critics predict. And central to those 
processes will be the choices that engineers, policymakers, CEOs and consumers make in the years 
ahead. 
Some jurisdictions are attempting to welcome A Vs, in the hope that high-tech jobs will follow. The 
results have been mixed, but overall A V testing to date has generally occurred in Silicon Valley, or 
other locations with either an historical presence of car development, good weather and traffic 
infrastructure. 
The downstream consequences that result from the widespread introduction of A Vs hard to 
predict. How will cities designed for human-controlled vehicles cope with robotic traffic? If 
commutes become painless and productive periods, what does that mean for urban sprawl and 
the environment? And how do our current experiences of algorithmic bias, unequal access, 
cybersecurity and privacy with digital systems like machine-learning and smartphones translate into 
a world of computer-controlled vehicles? 
The great disruption
Digital technologies have already transformed the way we interact with one another, the way we 
shop, the way we work, and the way we consume entertainment. Now Silicon Valley wants to reboot 
the last analog icon of the 20th century: the private motor car.
9 Toyota, “Toyota Research Institute Releases Video Showing First Demonstration of Guardian and Chauffeur 
Autonomous Vehicle Platform, ” September 27 2017, https://corporatenews.pressroom.toyota.com/releases/
toyota+research+institute+video+first+demonstration+guardian+chauffeur+autonomous.htm
10 California Department of Motor Vehicles, “Report of Traffic Collision Involving an Autonomous Vehicle, ” https://www.dmv.ca.gov/
portal/dmv/detail/vr/autonomous/autonomousveh_ol316+
11 Meredith Walker et al, “ AI Now Report 2018. ” AI Now Institute, December 2018. Available at https://ainowinstitute.org/AI_
Now_2018_Report.pdf 4   |   Ethics, Technology, and Public Policy – Autonomous VehiclesThe justification for disrupting transportation is usually presented in stark terms. The world is 
globalizing, urbanizing and populating rapidly. If we continue as we’re going, the planet will have an 
extra 4 billion cars by 2050 – two for each of the 2 billion extra people expected to be living here. Cars 
are massive energy hogs, pump out pollution, and kill over a million people in crashes annually, to 
say nothing of the cumulative years we waste sitting in traffic jams.12
An optimistic 2015 study estimated that shifting to A Vs would provide societal benefits of between 
$2000 and $4000 per car.13 The majority of the savings would be from fewer crashes, injuries and 
deaths, based on an assumption that A Vs would reduce the number of collisions by 90 percent. 
But A Vs were also predicted to be more rational motorists than humans, hewing to speed limits, and 
driving more smoothly and efficiently. Vehicle-to-vehicle communications can enable platooning, 
which means shorter following distances and better fuel economy. Even a few A Vs on freeways 
is projected to reduce the propagation of traffic-destabilizing shockwaves from unnecessary 
acceleration and braking. Studies suggest that (electric) A Vs can reduce emissions significantly, on a 
mile-for–mile basis.14 
The introduction of autonomous shared mobility services is expected to have massive impacts. 
Because the largest cost of traditional taxi services is the time of taxi drivers, MAAS using A Vs is 
projected to be significantly cheaper, thus increasing access to mobility among the elderly, disabled 
and children. It will also make financial sense for some, or even most, people to use MAAS instead 
of owning their own vehicles, thus reducing the total number of cars in a city, and particularly in 
parking lots.15 
Of course, that same process will cannibalize ridership of public transit services – something that 
is already being seen today with ride-sharing services from Uber and Lyft. Research in seven major 
US cities found that up to 60 percent of ride-hailing car trips would otherwise have been made by 
walking, biking, or transit, or not made at all.16 A Vs may siphon off enough bus and train riders that 
the model of truly public transportation is not sustainable outside the largest cities. The result could 
be the privatization of all transportation.
An additional issue for MAAS is that A Vs do not simply go from a user’s origin to their destination, 
as with traditional commuting today, but instead have to subsequently transit to the next customer. 
These so-called “zombie cars”, with no human occupants, represent increased congestion. A recent 
study suggests that current MAAS apps add 2.6 vehicle miles travelled for each mile of personal car 
transportation removed.17  Highly automated cities in the future could be home to far fewer vehicles 
overall than today, and yet experience much worse traffic and pollution.
12 The National Academies of Science, “2015 Urban Mobility Scorecard, ” August 2015,https://trid.trb.org/view/1367337
13 Daniel J Fagnant, Kara Kocelman, “Preparing a nation for autonomous vehicles: opportunities, barriers and policy 
recommendations, ” Transportation Research Papers Part A, Vol 77, July 2015, available at https://www.sciencedirect.com/science/
article/pii/S0965856415000804
14 Urbanism Next Center, “ AVs in the Pacific Northwest, ” University of Oregon, August 2018, available at https://cpb-us-e1.wpmucdn.
com/blogs.uoregon.edu/dist/f/13615/files/2018/09/AVs-in-Pacific-NW-Baseline-Report-Aug2018-Final-1j90css.pdf
15 A parking company in San Diego reports that ride-sharing services has already reduced parking by up to 50 percent at some times. 
Jeanette Steel, The San Diego Union-Tribune, February 22 2018, http://www.sandiegouniontribune.com/business/growth-development/
sd-fi-ace-parking-uber-lyft-competition-20180222-story.html
16 Regina R Clelow, Gouri Shankar Mishra, “Disruptive Transportation: The Adoption, Utilization, and Impacts of Ride-Hailing in 
the United States, ” UC Davis Institute of Transportation, October 2017, available at https://itspubs.ucdavis.edu/wp-content/themes/
ucdavis/pubs/download_pdf.php?id=2752
17 Schaller Consulting, “The New Automobility: Lyft, Uber and the Future of American Cities, ” July 25 2018, available at http://www.
schallerconsult.com/rideservices/automobility.pdf Ethics, Technology, and Public Policy – Autonomous Vehicles  |   5This work is licensed under a Creative Commons Attribution 4.0 International License.Some cities18 considering A Vs are also concerned about their effect on equity, racial and social justice. 
MAAS using A Vs will likely require well-maintained and mapped roadways, stable socio-economic 
conditions and, especially at first, relatively wealthy people who can afford to use them. Poorer, rural 
communities with low population densities and weak connectivity are likely to be the last to see 
MAAS. At the same time, A Vs seem likely to reduce urban livability: A Vs enable longer commutes, 
thus contributing to the growth of sprawling, polluting19 exurbs. They may also hollow out 
government revenues from car taxes, gas duties (if electric vehicles come to dominate), and parking 
and traffic fines (assuming A Vs are uniformly law abiding). 
The flipside of any radically disruptive technology is the people it disrupts. There are at least 4 
million professional drivers in the US: 1.75 million truckers,20 1.4 million delivery drivers,21 700,000 
bus drivers,22 and 300,000 taxi drivers.23 There are likely several million more full- or part-time ride-
hail drivers. Many of these jobs are threatened by fully competent A Vs, particularly on the taxi and 
ride-hail front. Truck, bus and delivery drivers typically have a wider range of tasks in their jobs, 
including loading and unloading, completing paperwork, and dealing with officials or the public, 
that could prove trickier to automate. 
Still, Goldman Sachs issued a research report last year that said A Vs could eliminate 25,000 jobs 
a month once the technology matures. That could be some time from now. Despite the apparent 
breakneck speed of A V development, the impact upon the wider job market will depend on how 
quickly they are deployed. New research24 from the American Center for Mobility estimates that, at 
worst, A Vs will displace only a few hundred thousand jobs in the coming decade, mostly in the late 
2020s.
Proponents of the widescale deployment of A Vs argue that not only will current drivers have plenty 
of time to retrain, the shift to MAAS will also create many new jobs, for example in map making, 
oversight, dispatch and A V maintenance. The long-term effect on auto manufacturing jobs, given the 
need for far fewer vehicles overall, is even less clear. 
With a technology as pervasive as the passenger car, it is difficult to predict all of the second- or 
third-order effects that could result from the widespread of adoption of competent A Vs. 
For a start, we live in a world with a staggering diversity of driving styles and cultures. Traffic rules 
and customs differ considerably around the world. Even within different societies, each human driver 
interacts with other roads users in a unique manner. A Vs will presumably drive far more consistently, 
or even identically, with unknown effects on safety, the environment and urban design at scale. Will 
people take to bicycles, electric scooters or other micro-mobility options en masse, now that they are 
(almost) certain not to be hit by a careless human driver? Perhaps pedestrians will reclaim city streets 
entirely, bullying cautious A Vs to the point that they are grid-locked and unable to move.
18Seattle Department of Transportation, “New Mobility Playbook, ” September 2017, available at https://www.seattle.gov/Documents/
Departments/SDOT/NewMobilityProgram/NewMobility_Playbook_9.2017.pdf
19 Jeffrey Wilson et al, “Blame the exurbs, not the suburbs, ” Energy Policy Volume 62, November 2013, available at https://www.
sciencedirect.com/science/article/pii/S0301421513006551
20 Bureau of Labor Statistics, “Occupational Employment and Wages, May 2017, ” https://www.bls.gov/oes/current/oes533032.htm
21 Bureau of Labor Statistics, “Occupational Outlook Handbook, ” https://www.bls.gov/ooh/transportation-and-material-moving/
delivery-truck-drivers-and-driver-sales-workers.htm
22 Bureau of Labor Statistics, “Occupational Outlook Handbook, ” https://www.bls.gov/ooh/transportation-and-material-moving/bus-
drivers.htm
23 Bureau of Labor Statistics, “Occupational Outlook Handbook, ” https://www.bls.gov/ooh/Transportation-and-Material-Moving/Taxi-
drivers-and-chauffeurs.htm
24 American Center for Mobility, “ Automated vehicles will create a shift in workforce demands, ” August 7 2018, https://www.
acmwillowrun.org/automated-vehicles-will-create-a-shift-in-workforce-demands/ 6   |   Ethics, Technology, and Public Policy – Autonomous VehiclesWill rates of alcohol and drug use soar now that people’s behaviors are not limited by driving? And 
in cities with expensive housing markets, will living from one’s car no longer be a stigma but a 
savvy career move? What are the implications for retail, and for traditional city centers, of cheaper 
delivery, or even shops and restaurants that can come to you? 
The good news is that none of these societal effects are likely to emerge overnight, or even on 
the extremely rapid timescale of the ongoing disruptions caused by MAAS such as Uber. For the 
foreseeable future, most A Vs will require expensive retro-fitted hardware or a new generation 
of production vehicles to emerge. That means academics, technologists and regulators should 
have time to experiment with and assess A V pilot projects as they look to avoid the least desirable 
outcomes that might result from the introduction of A V technology. 
Making judgments about that technology requires deciding which of A Vs’ many possible benefits 
are most important. Should societies prioritize keeping drivers safe, minimizing all road deaths, 
eliminating urban congestion, or addressing what many believe to be the existential threat of climate 
change? 
In imagining what a society fully disrupted by A Vs  might look like, it is useful to have an 
understanding of the technologies that today’s (and tomorrow’s) A Vs use.
Eyes, ears and brains
Good vision is all that human dr ivers need to be allowed behind the wheel.25 Motoring infrastructure 
is designed to accommodate the human eye: road signs, for example, are sized precisely to ensure 
that human drivers see them with enough time to follow their instructions. 
All A Vs on public roads use video cameras to observe their surroundings. The video data is fed to a 
computer vision system that interprets what it is seeing, usually based on extensive training done in 
the real world along with computer-generated simulations. 
Cameras can be used to localize the car – that is, determine its position within a lane or on a road. 
Vision systems can also read road signs, detect the state of traffic lights, and identify other road users 
and obstacles, just as a human driver would. 
But no digital camera used in A Vs today is as capable and flexible as the human eye, especially in very 
bright, dim or rapidly changing conditions. Most A V developers supplement cameras with additional 
sensors, to extend the car’s sensing abilities and provide redundancy. Radars are excellent for giving 
information about the road far ahead, and can operate well in rain, snow or fog. They do not have 
the resolution to accurately determine the size or shape of objects, however, and so cannot usually 
identify objects. 
Automotive radars are a fairly mature technology, having been developed over decades for collision 
warning systems. A more recent invention, and closely associated with self-driving vehicles, is lidar. 
An acronym of light detection and ranging, lidar systems use brief pulses of laser light to illuminate 
the road ahead, detecting and identifying objects to build up a three-dimensional model of the 
vehicle’s surroundings. 
Early rooftop lidars spun around to capture a 360-degree view, and were very expensive, often 
multiples of the cost of the car itself. Some newer configurations are cheaper and less conspicuous, 
utilizing small, cheaper solid state lidar units. Lidars generally have a higher resolution but a shorter 
range than radars, and are more susceptible to weather conditions like rain, snow and fog. 
25 Commercial truck drivers in the US and elsewhere also have to pass a hearing test.  Ethics, Technology, and Public Policy – Autonomous Vehicles  |   7This work is licensed under a Creative Commons Attribution 4.0 International License.Tesla Motors famously eschews the laser sensors in its Autopilot driver assist system. CEO Elon Musk 
calls lidars “a crutch that will drive companies to a local maximum that they will find very hard to get 
out of.”26 Comma.AI, a DIY driver-assist technology start-up, agrees. “Whenever someone says you 
need lidar for self-driving, ask them if they can drive a car. When they say yes, ask them where their 
lidar is,” tweeted its founder George Hotz last year. 27 Another reason for Musk and Hotz’s opposition 
to the technology may be that the use of lidars would vastly increase the prices of Tesla’s and 
Comma’s systems, both of which are commercially available today – although neither facilitates fully 
autonomous driving.
Most A V companies find lidar a useful sensor to increase their vehicles’ awareness and cover possible 
failures and edge cases with radar and vision systems. The consensus view is that lidars will fall in 
price faster than vision-based systems will improve.28 
All A Vs rely on GPS (or other satellite location systems) to provide a rough location fix and enable 
urban navigation, and many also have small ultrasonic sensors to detect cars and obstacles at 
short ranges, when parking or travelling alongside another vehicle, for example. Emerging sensor 
innovations include infrared cameras29 and even ground-penetrating radar.30 
Self-driving systems have intense computational needs, requiring powerful computers to handle 
sensor fusion, decision making and robotic control of the vehicle. Virtually all autonomous systems 
are designed to be self-contained within the vehicle. This reduces both the risk of remote hacking 
and of communications failures preventing operation. 
However, a few companies are actively exploring remote control. Phantom Auto31 is building a 
system, using commercial mobile broadband services, that can allow a human hundreds of miles 
away to take control of an A V should its on-board systems fail. For the moment, it is intended to help 
companies developing A V research vehicles.
Starsky Robotics32 is looking further ahead, with a remote driving solution for semi-trucks. It 
envisages its system allowing licensed truckers to remotely control autonomous vehicles during 
tricky situations like urban transits or loading and unloading. 
Even notionally self-contained A Vs rely on large, technically complex systems outside the vehicle. 
Companies need to develop and train computer vision and other AI systems long before they are 
deployed in the real world, and likely all run detailed simulations to work through hazardous 
situations that they are unlikely to encounter in reality. Waymo says that its vehicles have covered 
hundreds of times as many miles in simulation as in reality - around seven billion compared to ten 
million as of October 2018.33 Automated MAAS services also require maintenance, dispatch, routing 
and customer support technology and personnel. 
26 Andrew J Hawkins, “Elon Musk still doesn’t think LIDAR is necessary for fully driverless cars, ” The Verge, February 7 2018, https://
www.theverge.com/2018/2/7/16988628/elon-musk-lidar-self-driving-car-tesla
27 Comma AI, Twitter, 25 May 2017, https://twitter.com/comma_ai/status/867961910980878336
28 Benedict Evans, “Tesla, software and disruption” , August 31 2018, https://www.ben-evans.com/benedictevans/2018/8/29/tesla-
software-and-disruption
29 Mark Harris, “Night Vision for Self-Driving Cars” , IEEE Spectrum, 18 October 2017, https://spectrum.ieee.org/cars-that-think/
transportation/self-driving/do-selfdriving-cars-need-night-vision
30 https://wavesense.io/
31 https://phantom.auto/
32 http://starsky.io/
33 John Krafcik, “Where the next 10 million miles will take us, ” Medium, October 10 2018, https://medium.com/waymo/where-the-
next-10-million-miles-will-take-us-de51bebb67d3  8   |   Ethics, Technology, and Public Policy – Autonomous VehiclesAnother relevant technology is vehicle-to-vehicle (V2V) communication.34 V2V-equipped vehicles 
broadcast size, speed, location, heading and acceleration data on short-range radio frequencies, and 
listen for the same from other road users. The vehicles can then calculate if they are likely to occupy 
the same space at the same time as, say, a truck just around the corner or pulling out into traffic. 
Theoretically, the same system could also be used to communicate with infrastructure like traffic 
lights and pedestrians traveling with similar equipment.
Although championed by governments in the US and the EU, V2V (or the more general V2X) has been 
slow to develop and even slower to deploy. Currently, only a few Cadillac cars in the US are equipped 
with V2V technology, and no country is mandating its adoption. (The current US administration 
backed away from earlier proposals to require V2V , estimated at costing about $350 per vehicle, by 
the early 2020s). 
Levels of automation
The technologies above can be implemented in many different ways, with wildly varying results. 
A major challenge to the commercial adoption and public acceptance of vehicle automation is 
confusion today about the actual abilities offered by vehicles on the market, or in development. 
In 2016, Mercedes-Benz ran a TV commercial35 for its E-class car with a voiceover saying “Is the world 
truly ready for a vehicle that can drive itself? Ready or not, the future is here.” The car had some 
driver assistance features like cruise control and lane control but was far from a fully self-driving 
vehicle. Following complaints to the Federal Trade Commission (FTC), Mercedes pulled the advert. 
Tesla has gotten into similar hot water with its Autopilot system. In March 2018, two consumer 
lobbying groups, Consumer Watchdog and The Center for Auto Safety, wrote36 to the FTC: “Tesla [is] 
deceiving and misleading consumers into believing that the Autopilot feature of its vehicles is safer 
and more capable than it actually is.” They pointed out Tesla adverts that claim “Full Self-Driving 
Hardware on All Cars” and Tesla videos showing the company’s vehicles driving themselves. 
The Society of Automotive Engineers has issued a standard37 for classifying the broad range of 
automotive automation into five discrete levels:
Level 0 – No driving automation. Your grandmother’s car when she learned to drive.
Level 1 – Automation that controls either only the lateral (lane keeping) or the forward (cruise 
control) motion of the vehicle. The driver remains responsible for detecting and responding to 
objects and hazards on the road.
Level 2 – Automation that controls both the direction and speed of the car in some circumstances 
(usually highways) but requires the driver to stay fully engaged. This would describe the current 
“beta phase” of Tesla’s Autopilot system. 
Level 3 – Conditional automation that can sustain the driving task, including object detection and 
avoidance, in limited situations. However, the driver must stay alert and intervene quickly when the 
system requests.
34 NHTSA, “Vehicle-to-Vehicle Communication, ” https://www.nhtsa.gov/technology-innovation/vehicle-vehicle-communication
35 Mercedes-Benz, “The Future, ” TV advert, July 2016, https://www.youtube.com/watch?time_continue=10&v=C0d5e1c_qo0
36 The Center for Auto Safety, Consumer Watchdog, letter to Federal Trade Commission, May 23 2018, available at https://www.
autosafety.org/wp-content/uploads/2018/05/CAS-and-CW-Letter-to-FTC-on-Tesla-Deceptive-Advertising.pdf
37 SAE International, “Taxonomy and Definitions for Terms Related to Driving Automation Systems for On-Road Motor Vehicles, ” June 
2018, https://www.sae.org/standards/content/j3016_201806/   Ethics, Technology, and Public Policy – Autonomous Vehicles  |   9This work is licensed under a Creative Commons Attribution 4.0 International License.Level 4 – A high level of driving automation that requires no input from humans inside the vehicle, 
but only in certain operational domains. These might specify highways, areas that have been well 
mapped, daytime driving or good weather. 
Level 5 – Full driving automation anywhere, and in all conditions, that cars would normally operate. 
Vehicles would not need to have manual driving controls. 
While these technologies fall along a spectrum, there is an important distinction between SAE Levels 
1 to 3, and Levels 4 and 5. The first three levels require the participation of a competent, licensed 
human driver, and are thus often lumped together as driver assistance or advanced driver assistance 
systems (ADAS). Cars with the highest two levels of automation could be transporting unlicensed or 
incompetent humans, or no one at all. 
Some companies, for example Tesla, Cadillac and Nissan, are already providing Level 2 systems as 
stepping stones to Level 4 and 5 vehicles. Deploying ADAS technologies allows companies to gain 
experience with real-world customers and to generate revenue to fund continued progress. 
However, there are concerns about the safety of such systems. Waymo abandoned the idea of 
commercializing a Level 3 system in 2013 after testing it among its Google employees, and watching 
them with cameras. It found that drivers were “tuning out” from the driving task – sometimes 
applying make-up, working on a laptop or even falling asleep (for nearly half an hour) while 
travelling at freeway speeds.38  Many39 scientific40 studies41 have found that human drivers rapidly lose 
their ability to concentrate when required to oversee automated systems.
Carmakers do their best to mitigate such lapses in attention by sensing when drivers take their hands 
from the wheel or their eyes from the road, and providing haptic or auditory alerts. Essentially, 
Level 2 and 3 systems need to watch both the road ahead and the driver behind their wheel. If the 
driver refuses to supervise it, the car will disengage and hand control back. This management of the 
human-computer relationship is an added complication that comes with its own risks, such as “mode 
confusion” when car and human both believe the other is in charge. 
So why do manufacturers bother with Level 2 and 3 at all? One reason is that media coverage of self-
driving cars has stimulated in interest among consumers in trying the technology, and Tesla and 
Cadillac have both enjoyed some success in presenting their systems as luxury convenience features. 
Perhaps more importantly, traditional car makers have no choice but to work with Level 2 and 3 
systems. The passenger car has usually been sold as a product that consumers expect to work over 
wide geographical and meteorological domains. This is in contrast to  an A V MAAS that start-ups like 
Waymo and Uber can roll out slowly, generally starting from the least challenging environments. 
If today’s car manufacturers wait until Level 4 and 5 systems are widely available, they may cede 
ground to start-ups which have no legacy customers to satisfy. 
38 Larry Burns, “ Autonomy, ” Ecco, August 2018,  page 238
39 Robert E Llaneras ,Jeremy Salinger, Charles A Green, “Human Factors Issues Associated with Limited Ability Autonomous Driving 
Systems: Drivers’ Allocation of Visual Attention to the Forward Roadway, ” 2013 Driving Assessment Conference, June 18 2013, 
available at https://ir.uiowa.edu/drivingassessment/2013/papers/15/
40 Matthew B Tucker et al, “Detection of Attentional State in Long-Distance Driving Settings Using Functional Near-Infrared 
Spectroscopy, ” Transportation Research Board, January 2016, available at http://hal.pratt.duke.edu/sites/hal.pratt.duke.edu/files/u10/
TRBSubmissionPaper_Revision_Final_11_18_2015.pdf
41 Stephen M Casner, Edwin L Hutchins, Don Norman, “The challenges of partially automated driving, ” Communications of the ACM, 
May 2016, available at https://dl.acm.org/citation.cfm?id=2830565 10   |   Ethics, Technology, and Public Policy – Autonomous VehiclesThere is also the possibility that truly reliable Level 5 systems may still be some decades away. 
Humans intuitively navigate the social complexities of everyday driving in ways that are extremely 
difficult to automate, an instance of what is called Moravec’s Paradox.42 Until completely driverless 
A Vs can prove themselves in the real world, we may be stuck with Level 2 and 3 vehicles for some 
time to come. 
History of A Vs
Driverless cars have been proposed, and tested, almost since the dawn of the motor car. One of 
the first real-world trials was by the Houdina Radio Company American Wonder in New York in 
1925.43 This involved a modified production sedan being remotely controlled by radio from a vehicle 
following it, on the streets of New York. 
By the 1950s, major car makers were dabbling with cars that could follow guide wires, circuits or 
cables embedded in the roadway. Experimental vehicles using vision systems and early lidar systems, 
controlled by on-board computers, emerged in the 1980s and 1990s. 
What supercharged the current wave of A Vs was a series of competitions organized by the US 
military’s research arm DARPA. The Grand Challenge44 in 2004 offered a $1m prize to an A V capable 
of completing a tough 150-mile off-road route in the Mojave Desert. None of the 15 vehicles that 
started got further than 7.5 miles along the course. A follow-up event the next year saw five vehicles 
complete the course, and an on-road Urban Challenge in 2007 specifically addressed typical traffic 
infrastructure, including intersections, road signs and other road users.
Core personnel from teams participating in the three DARPA challenges went on to develop many 
of the A Vs that are being tested and operated today. Google in particular hired numerous engineers, 
led by Stanford computer science professor Sebastian Thrun, to work on mapping and then A V 
technologies in 2007 and 2008.
When Google’s “self-driving cars” were revealed in 2010, already having been extensively tested on 
public roads, the A V gold rush began. Within a few years, dozens of start-ups had begun work on 
either A Vs themselves, or the sensor and computing technologies they use. Established automakers 
were slower to the party but by 2016 most major car makers either had an in-house A V program, or 
had acquired one or more start-ups to boost their A V expertise. 
The financial stakes are high. In 2017, Waymo (Google’s spun-off self-driving car unit) sued Uber for 
patent infringement (initially) and misappropriation of trade secrets, relating to accusations that 
longtime Google engineer Anthony Levandowski took thousands of technical documents with him 
when he left the company. Levandowski then started a self-driving truck start-up called Otto, which 
was quickly acquired by Uber, along with numerous ex-Google engineers. 
The high profile and acrimonious lawsuit was ultimately settled by Uber giving Google a small stake 
in its business, but not before both companies were damaged by revelations of corporate chaos and 
shady practices.45 
42 Hans Moravec, “Rise of The Robots, ” Scientific American, March 23 2009, https://www.scientificamerican.com/article/rise-of-the-
robots/
43 Carl Engelking, “The ‘Driverless’ Car Era Began More Than 90 Y ears Ago, ” Discover, December 13 2017, http://blogs.
discovermagazine.com/d-brief/2017/12/13/driverless-car-houdina-houdini/#.W5qbaOhKiUk
44 DARPA, “Grand Challenge, ” http://archive.darpa.mil/grandchallenge/
45 Aarian Marshall, Alex Davies, “The end of Waymo v. Uber marks a new era for self-driving cars: reality, ” Wired, February 9 2018, 
https://www.wired.com/story/uber-waymo-trial-settlement-self-driving-cars/ Ethics, Technology, and Public Policy – Autonomous Vehicles  |   11This work is licensed under a Creative Commons Attribution 4.0 International License.Legal status of self-driving vehicles
Prior to 2010, no jurisdiction in the world had enacted laws regarding the testing or operation of A Vs 
on public roads. That worked to Google’s advantage, once its engineers considered the prototype car 
was reliable enough to operate incognito among human drivers in California.
Google’s lawyers scoured the state’s driving regulations and noted that nothing in the texts explicitly 
prevented a computer from operating a vehicle, as long as a licensed human driver was overseeing it 
from the driver’s seat.46 The human would remain legally liable for any infractions or collisions. 
But this was clearly a stopgap measure. Google realized that once it was widely known that A Vs were 
more than just a science fiction concept, law makers would be keen to have input into how those 
vehicles operated on their roads. In 2011, the company began discussions with officials in California, 
but those progressed only slowly. 
Google, and specifically Anthony Levandowski – the same engineer who had built Google’s first 
self-driving car and later the protagonist of the Google-Uber lawsuit – started to look elsewhere. 
Levandowski made contact with a lobbyist, David Goldwater, who suggested that a smaller state like 
Nevada might be more open to creating friendly legislation. 
Between them, Levandowski and Goldwater drafted a bill, AB511,47 which defined an A V as “a motor 
vehicle that uses artificial intelligence, sensors and global positioning system coordinates to drive 
itself without the active intervention of a human operator.” It would also open the door to testing and 
operating A Vs in the state.
“When we worked with the Nevada legislature, [Anthony took] a low profile and back seat to 
everything,” says Goldwater, in a previously unpublished interview. “It was not where we wanted 
to announce that this was Google and this was a big deal. It was strategic on his part, which I 
encouraged, that we keep [their] profile down and get as far as we could without too many people 
paying attention.”
Nevada passed that bill in August 2011, becoming the first jurisdiction to legalize A Vs. “Nevada was 
about removing an excuse for the engineers to not be able to ship the technology,” said Levandowski 
in 2016. “Once the roadblock was removed, it was more clear that we had to do more work to improve 
the reliability of the tech.  That’s really when I realized, it’s not ready.”
Nevertheless, Google was swift to capitalize on the PR opportunity. The bill became law in March 
2012, and in May, Google put a modified Toyota Prius through the world’s first “self-driving test.”48 A 
driving examiner from the Nevada Department of Motor Vehicles (DMV) sat in the passenger seat 
while the car drove itself through Las Vegas, just as a human applicant would. Although Google had 
chosen the route and its engineer/driver, Chris Urmson, had to take control of the car twice during 
the test, the vehicle passed and was awarded a special red A V license plate.  
Google never tested extensively in Nevada, but the state’s A V laws would come to the fore again a few 
years later. When Levandowski left Google to launch his self-driving truck start-up Otto in 2016, he 
filmed a demonstration video of his first autonomous semi-truck barreling down a Nevada highway 
with no one in the cab. However, that truck had not had its self-driving test and was not carrying an 
A V license plate.49
46 Larry Burns, “ Autonomy, ” Ecco, August 2018,  Page 176
47 Assembly Bill No. 511, State of Nevada, available at https://www.leg.state.nv.us/Session/76th2011/Bills/AB/AB511_EN.pdf
48 Mark Harris, “How Google’s Autonomous Car Passed the First U.S. State Self-Driving Test, ” IEEE Spectrum, September 10 2014, 
https://spectrum.ieee.org/transportation/advanced-cars/how-googles-autonomous-car-passed-the-first-us-state-selfdriving-test
49 Mark Harris, “How Otto Defied Nevada and Scored a $680m Payout From Uber, ” Wired, November 28 2016, https://www.wired. 12   |   Ethics, Technology, and Public Policy – Autonomous VehiclesThe Nevada DMV  had warned Otto that engaging its technology on the state’s road without a permit 
would be a violation of its A V testing regulations. Levandowski thought he knew better. Having 
helped to draft those rules, he spied a loophole in them. AB511 defines an A V as one that operates 
“without the active intervention of a human operator.” Levandowski claimed that Otto’s truck had a 
safety driver sitting, unseen, further back in its cab, ready to take over should the system fail. “Our 
vehicle still requires monitoring, so it’s not an A V ,” said Levandowski.
The DMV took a dim view of Levandowski’s interpretation and called Otto’s vehicles illegal. But 
Levandowski must also have known that Nevada’s existing rules had no provisions or penalties for 
anyone breaking them. No action was taken, and Otto was acquired shortly after by Uber. 
Since Nevada’s pioneering effort, 28 other US states have enacted legislation relating to A Vs.50 The 
neighboring states of California and Arizona, at opposite ends of the legislative spectrum, neatly 
illustrate some of the problems in formulating robust, effective regulation for a technology that is 
still evolving rapidly.
California’s path to A V regulation has been more thorough and transparent than perhaps any other. 
The process has also been stately, not to say slow. Despite talking with Google as early as 2011, it was 
not until 2013 that the state held its first public workshops about A V testing, and not until fall 2014 
that its first A V testing regulations51 went into effect. 
California’s rules go into far more detail about A V technology than Nevada’s. Although there is no 
explicit self-driving test, manufacturers must post a large ($5m) bond in case of claims, report every 
collision involving their vehicles, and supply an annual report of “disengagements” – unplanned 
deactivations of their autonomous technology. 
Because these reports52 are some of the only standardized public documents detailing often 
secretive A V programs, they have understandably (if sometimes erroneously) come to be regarded as 
measuring the relative performance53 of the companies’ technologies. 
Commenting on the figures in 2016, Google’s then-lead engineer Chris Urmson said, “What you don’t 
get without me talking to you is the fact that [the number of disengagements] isn’t really something 
we put a lot of focus on. And that it really isn’t representative of where the technology would be when 
we’re ready to release it.”
California is now granting permits for fully driverless54 cars to begin testing in public, and is already 
thinking about the deployment of A V MAAS. The driverless test vehicles are required to stick to geo-
fenced areas and certain weather conditions, and need to have a remote human operator to assist 
passengers. Cars also need to have a plan of how they would interact with law enforcement and 
other emergency services.55 California is also planning to extend its A V regulations to cover light 
commercial delivery vehicles.
com/2016/11/how-otto-defied-nevada-and-scored-a-680-million-payout-from-uber/
50 National Conferences of State Legislatures, “Self-driving vehicles Enacted Legislation, ” http://www.ncsl.org/research/transportation/
autonomous-vehicles-self-driving-vehicles-enacted-legislation.aspx
51 California Department of Motor Vehicles, “ Adopted Text for Testing of Autonomous Vehicles, ” https://www.dmv.ca.gov/portal/wcm/
connect/a6ea01e0-072f-4f93-aa6c-e12b844443cc/DriverlessAV_Adopted_Regulatory_Text.pdf?MOD=AJPERES
52 California Department of Motor Vehicles, “ Autonomous Vehicle Disengagement Reports 2017, ” https://www.dmv.ca.gov/portal/dmv/
detail/vr/autonomous/disengagement_report_2017
53 Andrew J Hawkins, “Waymo and GM still lead the pack in California’s new self-driving report cards, ” The Verge, January 31 2018, 
https://www.theverge.com/2018/1/31/16956902/california-dmv-self-driving-car-disengagement-2017
54 California Department of Motor Vehicles, “Driverless Testing of Autonomous Vehicles, ” https://www.dmv.ca.gov/portal/dmv/detail/
vr/autonomous/auto
55 Mark Harris, “Waymo Filings Give New Details on Its Driverless Taxis, ” IEEE Spectrum, May 14 2018, https://spectrum.ieee.org/cars-
that-think/transportation/self-driving/waymo-filings-give-new-details-on-its-driverless-taxis Ethics, Technology, and Public Policy – Autonomous Vehicles  |   13This work is licensed under a Creative Commons Attribution 4.0 International License.Regulators stru ggled with how much input local towns and cities should have into the cars’ 
operations. “In the past, we’ve said they would have to work on a plan with local authorities, but if 
you have a vehicle designed to go through three different jurisdictions, that would be a tough task,” 
said Bernard Soriano, deputy director of the CA DMV in 2017. Instead, the agency worked with the 
California Highway Patrol to settle on a single, state-wide process. 
A V developers have generally complied with California’s detailed regulations. One notable exception 
is Anthony Levandowski once again. After his move to Uber, Levandowski was put in charge of the 
ride-hail company’s A V program. In December 2016, Uber deployed a fleet of A V passenger cars in 
San Francisco without first applying for an A V testing permit. Levandowski’s rationale was the same 
as he had used in Nevada with Otto: because Uber’s cars required a safety driver to monitor them, 
they did not actually count as autonomous vehicles. 
This time, Levandowski did not get away with it. The California DMV sent Uber a letter calling 
the company’s behavior illegal and threatening legal action if the vehicles were not removed. 
“This technology holds the promise of true safety benefits on our roadways, but must be tested 
responsibly,” it wrote.56  Uber did not back down, and the DMV subsequently revoked the 
registrations of Uber’s 16 A Vs. 
Levandowski swiftly transported the A Vs to Arizona (on an Otto truck, naturally), where they were 
eagerly welcomed by Arizona governor Doug Ducey. “While California puts the brakes on innovation 
and change with more bureaucracy and more regulation, Arizona is paving the way for new 
technology and new businesses,” he wrote in a statement.57 Ducey had long been wooing Uber. In 
2015, Ducey had signed an executive order (drafted with contributions from Uber) that cleared the 
way for the public testing and operation of A Vs, with no permits or bonds, and very little oversight. In 
fact, Uber’s A Vs were already being quietly, if not secretly, tested in Arizona when the additional San 
Francisco cars arrived.58 
Arizona was the very model for laissez faire operation of A Vs. The governor’s A V oversight committee 
was stuffed with political appointees and had met only once or twice, calling no witnesses and 
issuing no recommendations. In January 2017, Ducey declared that Arizona’s approach to self-driving 
technology would be “the opposite approach” to California. By early 2018, about half of Uber’s entire 
200-strong fleet of A Vs would be based in the state. 
At the start of March 2018, Ducey issued another executive order,59 clearing the way for the operation 
of fully driverless A Vs. Just over two weeks later, one of Uber’s A Vs struck and killed a pedestrian 
crossing the road in Tempe, while its safety driver was watching streaming video on their phone.60 
Eight days after that, Ducey suspended Uber’s A V testing program in the state, saying that a video of 
the incident raised concerns about the company’s ability to safely test its technology. 
It later emerged that a manager in Uber’s testing operation group had previously warned executives 
that the software driving the company’s vehicles was dangerous, that human safety drivers were not 
properly trained, and that the cars are “routinely in accidents re sulting in damage.”61
56 Alison Griswold, “Letter: California’s DMV says Uber “must cease” operating its self-driving cars, ” Quartz, December 14 2016, 
https://qz.com/863718/uber-received-a-stern-letter-from-the-california-dmv-telling-it-to-cease-operating-its-self-driving-cars/
57 Office of the Governor, “Governor Ducey Tells Uber ‘CA May Not Want Y ou, But AZ Does’ , ” December 22 2016, https://azgovernor.
gov/governor/news/2016/12/governor-ducey-tells-uber-ca-may-not-want-you-az-does
58 Mark Harris, “ Arizona governor and Uber kept self-driving program secret, emails reveal, ” The Guardian, March 28 2018, https://
www.theguardian.com/technology/2018/mar/28/uber-arizona-secret-self-driving-program-governor-doug-ducey
59 Office of the Governor, Executive Order, April 2018, https://azgovernor.gov/sites/default/files/related-docs/eo2018-04_1.pdf
60 Daisuke Wakabayashi, “Self-Driving Uber Car Kills Pedestrian in Arizona, Where Robots Roam, ” The New Y ork Times, March 19 
2018, https://www.nytimes.com/2018/03/19/technology/uber-driverless-fatality.html
61 Amir Efrati, “How an Uber Whistleblower Tried to Stop Self-Driving Car Disaster, ” The Information, December 10 2018, https://
www.theinformation.com/articles/how-an-uber-whistleblower-tried-to-stop-self-driving-car-disaster 14   |   Ethics, Technology, and Public Policy – Autonomous VehiclesIt is, of course, impossible to know whether the fatal collision might have been avoided had Uber 
been operating legally at the same scale in California, where any technological or procedural 
shortcomings might have come to light earlier thanks to the state’s reporting requirements of 
collisions and disengagements. 
The high profile example of Uber moving its testing from California to Arizona aside, it is also 
difficult to unpack the stimulating or depressing effect of A V regulations from the particular 
economic and geographical conditions of individual locations. California has the largest number of 
companies testing A Vs (57 as of September 2018), largely due to the density and vitality of its start-
up ecosystem. And Arizona and Florida probably attract testers as much for their generally clement 
weather and wide-open roads as for any laws that their governments might have passed. 
It might suffice to note simply that despite having the most detailed and burdensome regulations of 
any US state, California continues to lead the way in the number and diversity of A V start-ups and 
larger operations.
There is an elephant in the room, however. While states have traditionally regulated the licensing 
and operation of drivers and vehicles, the federal government has long held sway over safety 
requirements.62 There have been several attempts to pass national laws regarding autonomous 
vehicles, laws that could particularly affect the more bureaucratic states like California. 
The latest US bill, and the one that has progressed the farthest, is the bipartisan A V START63 (Safer 
Transportation through Advancement of Revolutionary Technologies) Act, which passed by voice 
vote in the House of Representatives in 2017. Proponents of the bill, which include many automakers, 
A V developers, and ride-share companies, rely heavily on US road deaths figures and the often-
quoted figure that 94 percent of collisions involve human error.64 
A V Start would apply to vehicles at SAE Level 3 and higher, and would allow manufacturers to 
seek exemptions to federal vehicle safety standards for vehicles that lack traditional controls, by 
proving their vehicles offered equivalent or greater safety. It obliges manufacturers to ensure that 
their vehicles can detect all types of road users, including pedestrians and cyclists. Once ready for 
commercial deployment or sale, manufacturers would then have to submit a Safety Evaluation 
Report detailing system safety, data recording, cybersecurity, human-machine interface, automation 
level, and crashworthiness. The bill also specifies that crash data be collected for partially automated 
(Level 1 and 2) vehicles.
But the Act also includes some loopholes. Although manufacturers have to provide the Department 
of Transportation (DOT) with their safety report, the Act specifically says that Secretary of 
Transportation cannot condition the sale or deployment of A Vs based on an evaluation of it. Under 
the rules, each manufacturer would be allowed to deploy 15,000 vehicles immediately, ramping up to 
80,000 A Vs by the third year after the legislation going into force. 
In July 2018, a group of road safety advocates published an open letter65 criticizing A V START and 
proposing a number of fixes. These include requiring A Vs to pass a “vision test” (hearkening back to 
Nevada’s “self-driving test”), compelling manufacturers to capture and share crash data, including 
Level 2 vehicles in the rules, and allowing states and local jurisdictions to enact their own A V 
regulation.
62 NHTSA, “FMVSS Regulations, ” https://www.nhtsa.gov/laws-regulations/fmvss
63US Congress, “S.1885 - AV START Act, ” https://www.congress.gov/bill/115th-congress/senate-bill/1885/text
64 Coalition for Future Mobility, “U.S. Senate Can Make History and Save Lives by Passing the AV START Act, ” September 6 2018, 
https://www.prnewswire.com/news-releases/us-senate-can-make-history-and-save-lives-by-passing-the-av-start-act-300708244.html
65 Letter at available at http://usa.streetsblog.org/wp-content/uploads/sites/5/2018/07/Letter-to-Senate-on-AV-START-Act-
July-16-2018.pdf Ethics, Technology, and Public Policy – Autonomous Vehicles  |   15This work is licensed under a Creative Commons Attribution 4.0 International License.Veteran auto safety campaigner Ralph Nader wrote of A V Start, “Autonomous-vehicle manufacturers 
argue that completely driverless cars would be safer than conventional cars, in that they would 
eliminate driver error and never get drunk. Yet the manufacturers are inebriated with power over 
Congress. They tout data-starved claims of innovative, revolutionary technologies premised on ‘if you 
build it they will come.’”66
Promisingly, there are signs that the industry is now thinking seriously about safety. In October 
2018, the Rand Corporation proposed (in partnership with Uber) a comprehensive integrated safety 
framework67 for A Vs that involves detailed testing and metrics to be gathered in order to establish 
statistically meaningful measures of safety. 
One of the main points of those against A V START, and why its backers have been unable to muster 
enough votes in the Senate, is that the National Transportation Safety Board (NTSB) has several 
investigations involving automation that could have a direct bearing on the new rules. A V technology 
may be safer in the long run, but it seems to be killing people now. 
Getting it right, and wrong
One re ason why A V developers are in such a rush to develop their vehicles and services is that many 
believe that A V MAAS will be a “winner takes all” scenario, in the tradition of Windows, Google and 
(possibly) Uber. Even in the presence of competent, or even superior, rivals, a technology product 
that launches either earlier or cheaper can enjoy market dominance.68 
Developing A Vs was considered “existential” to Uber’s future by its founder Travis Kalanick. The logic 
is that the first company to offer an A V MAAS will be able to undercut all other taxi and ride-hail 
services. 
Analysts at ARK Investment Management estimate that an A V MAAS might cost users 35 cents a 
mile.69  That compares to around $1 to $1.50 per mile for ride-hail services like Uber or Lyft70 or 
around 59 cents a mile for the average private car.71 The first A V MAAS could either be very profitable, 
thus fueling its expansion, or very cheap, thus grabbing market share, or possibly even both. 
There are other potential benefits to being first to market. The first mover could gain valuable 
insights into customer behaviors, helping them to deploy more efficiently, or rapidly improve their 
maps and understanding of particular urban and geographical domains. 
But no one knows whether such dominance is likely. An equally plausible scenario could be 
providers rushing to deploy, only to face mounting capital costs, unexpected technological problems 
and pushback from users and communities. While social media’s global reach seems inevitable these 
days, Facebook’s vaunted network effect took hold too late for predecessors such as Friends Reunited 
and MySpace.
66 Ralph Nader, “Driverless-Car Legislation Is Unsafe at This Speed, ” The Wall Street Journal, August 22 2018, https://www.wsj.com/
articles/driverless-car-legislation-is-unsafe-at-this-speed-1534973755#
67 The Rand Corporation, “Measuring Automated Vehicle Safety, ” 2018, available at https://www.rand.org/pubs/research_reports/
RR2662.html
68 Charles Arthur, “Tech products keep falling into the same market share pattern, ” Business Insider, December 12 2015, https://www.
businessinsider.com/tech-product-market-share-pattern-2015-12
69 Tasha Keeney, “ Autonomous Taxis: Who Will Reap the Revenues and Profits from the Boom Ahead?” February 22 2018, https://ark-
invest.com/research/autonomous-taxi-revenues#fn-33824-2
70 F Todd Davidson, Michael E Webber, “If Y ou Drive Less Than 10,000 Miles a Y ear, Y ou Probably Shouldn’t Own a Car, ” City Lab, 
October 16 2017, https://www.citylab.com/transportation/2017/10/if-you-drive-less-than-10000-miles-a-year-you-probably-shouldnt-
own-a-car/542988/
71 AAA, September 13 2018, https://newsroom.aaa.com/auto/your-driving-costs/ 16   |   Ethics, Technology, and Public Policy – Autonomous VehiclesThere have only been a few, limited deployments of A V MAAS to date. The largest is from Waymo, 
which launched what it calls an Early Rider72 program in and around Phoenix, Arizona in April 
2017, and a commercial service to the same community in December 2018, called Waymo One. The 
initially deployed service typically has safety drivers behind the wheel of its A Vs. It currently allows 
around 400 people to summon cars via a smartphone app and take rides around the city. Voyage Auto 
is offering a similar pilot service, entirely within two retirement communities73 in California and 
Florida. Lyft has completed over 5000 A V rides in Las Vegas, with its technology partner Aptiv.74 Other 
A V developers, including GM and Uber, are also poised to launch services.
Waymo’s and Voyage’s geographically limited deployments have been largely uncontroversial, 
although there have been reports of Waymo’s vehicles irritating human drivers with hesitant and 
overly cautious maneuvers.75 As of December 2018, police in Waymo’s test area had received 21 
reports of citizens harassing the autonomous vehicles and their human test drivers, including tires 
being slashed, cars being forced off the road, and even having a handgun aimed at them.76
Other companies have had just as bumpy a time of it. Even before one of Uber’s A V hit and killed a 
pedestrian in Tempe, the company’s vehicle had been spotted running red lights77 in San Francisco. 78  
But the company that has faced the most sustained criticism and scrutiny is Tesla. Tesla’s Autopilot 
has been standard on its cars from October 2014, although use of the system requires an additional 
payment. Over the years, the hardware has changed, including as the result of an acrimonious split 
with the original vendor for its vision system, Mobile ye, in July 2016. In October 2016, Tesla said that 
all of its new cars would now come with all the hardware they need for Level 5 operation, with driver 
assistance and self-driving features being rolled out slowly as they were developed. As of autumn 
2018, Autopilot supports Level 2 driver assistance. 
Since its debut there have been a handful of serious collisions, and three fatalities, linked to use of 
Autopilot. Three involved Tesla vehicles colliding with stationary vehicles, which is a known problem 
with A V technologies that rely on radar. One of the two US fatalities happened in Florida in 2016, 
when a Tesla Model S did not detect a tractor-trailer crossing the road in front of it and subsequently 
hit it at about 75mph. The second, which occurred in Mountain View California in 2018, involved a 
Tesla Model X driving into a highway divider at high speed.
The National Transportation Safety Board (NTSB) determined that the Florida crash was due to a 
number of factors, including poor driving by the truck driver and over-reliance on the automated 
system by the Tesla driver. Tesla itself did not escape blame, with NTSB Chairman Robert Sumwalt, 
commenting: “System safeguards, that should have prevented the Tesla’s driver from using the car’s 
automation system on certain roadways, were lacking and the combined effects of human error and 
the lack of sufficient system safeguards result ed in a fatal collision that should not have happened.”79
72 https://waymo.com/apply/faq/
73 https://voyage.auto/communities/
74 “Celebrating 5,000 Self-Driving Rides with Aptiv, ” August 21 2018, https://blog.lyft.com/posts/lyft-aptiv-5000
75 Amir Efrati, “Waymo’s Big Ambitions Slowed by Tech Trouble, ” The Information, August 28 2018, https://www.theinformation.com/
articles/waymos-big-ambitions-slowed-by-tech-trouble
76 Ryan Randazzo, “ A slashed tire, a pointed gun, bullies on the road: Why do Waymo self-driving vans get so much hate?, ” AZ Central, 
December 11 2018, https://www.azcentral.com/story/money/business/tech/2018/12/11/waymo-self-driving-vehicles-face-harassment-
road-rage-phoenix-area/2198220002/
77 Andrew Liptak, “ A self-driving Uber ran a red light last December, contrary to company claims, ” The Verge, February 25 2017, 
https://www.theverge.com/2017/2/25/14737374/uber-self-driving-car-red-light-december-contrary-company-claims
78 Andrew Liptak, “ A self-driving Uber ran a red light last December, contrary to company claims, ” The Verge, February 25 2017, 
https://www.theverge.com/2017/2/25/14737374/uber-self-driving-car-red-light-december-contrary-company-claims
79 National Transportation Safety Board, “Driver Errors, Overreliance on Automation, Lack of Safeguards, Led to Fatal Tesla Crash, ”  Ethics, Technology, and Public Policy – Autonomous Vehicles  |   17This work is licensed under a Creative Commons Attribution 4.0 International License.NTSB made a number of recommendations, including that manufacturers should incorporate 
safeguards to limit the use of A V systems to conditions for which they are designed, for there to be 
a method to verify those safeguards, and for development of applications to more effectively sense 
a driver’s level of engagement with the driving task. The NTSB is continuing to investigate the more 
recent collisions involving Autopilot, and in April slapped Tesla’s wrist for revealing investigative 
information before it was vetted.80
Tesla, however, continues to roll out new Autopilot features even as its original technologies are 
being investigated. In September 2018, a driver using a new Summon feature, which automatically 
extracts the Tesla from a parking space, said their vehicle veered into a garage wall and lost its 
front end. “You are responsible for the operation of your vehicle even during summon mode,” the 
company reportedly told him in an email.81
The tension between Tesla’s commercial desire to bring an exciting product to market, and the safety 
imperative to ensure that it works, is far from being resolved. In October 2018, Tesla quietly removed 
the option for customers to pre-order a Level 5 Autopilot package for its latest Model 3 sedan. Does a 
first mover advantage disappear if you shift into reverse?
Can you sue a robot?
The question of who is responsible for cars operating autonomously has yet to be fully settled. While 
humans are required to have some input into the driving task (automation Levels 1 through 3), 
liability rests with the vehicle’s licensed driver. During A V MAAS, the liability will almost certainly 
rest with the service operator. Voyage recently revealed that it was pioneering a concept of real-time 
insurance,82 where premiums could be dynamically adjusted depending on the risk profiles of an A V’s 
operating environment. 
Privately-owned Level 4 and 5 vehicles are a gray area. Bryant Walker Smith of the University of 
South Carolina’s School of Law has argued83 that A Vs herald a transition from vehicular negligence to 
product liability. Today, around 2 percent of crashes are directly attributable to component failure, 
and up to 94 percent to human error. In one possible A V future, those figures might be reversed – 
albeit with a vastly reduced number of crashes overall. 
One consequence of this, notes Walker Smith, is that the costs associated with such accidents would 
be borne by the manufacturer, and ultimately be reflected in the purchase price of the car. In effect, 
an objectively safer Level 5 car might cost more than its Level 3 equivalent. 
If A Vs live up to even some of their promise, however, the overall cost to society from vehicular 
crashes should be lowered. A 15 percent decline in collisions would reduce annual US costs by $125 
billion, while replacing 10,000 fatal injuries with 10,000 minor injuries would reduce costs by $90 
billion more.84 It is surely this hope that led Volvo CEO Håkan Samuelsson to declare in 2015 that his 
company would accept full liability whenever one of its cars was in autonomous mode.
September 12 2017, https://www.ntsb.gov/news/press-releases/Pages/PR20170912.aspx
80 National Transportation Safety Board, “NTSB Revokes Tesla’s Party Status, ” April 12 2018 https://www.ntsb.gov/news/press-releases/
Pages/NR20180412.aspx
81 Aaron Mak, “It’s Not Been a Great Day of News for Tesla’s Autopilot, ” Slate, September 13 2018, https://slate.com/technology/2018/09/
tesla-autopilot-problems-elon-musk.html
82 Voyage, “ Auto Insurance for the Autonomous Age, ” July 25 2018, https://news.voyage.auto/auto-insurance-for-the-autonomous-age-
262d5e985949
83 Bryant Walker Smith, “ Automated Driving and Product Liability, ” Michigan State Law Review Vol.1 2017, available at https://papers.
ssrn.com/sol3/papers.cfm?abstract_id=2923240
84 National Safety Council, “Estimating the Costs of Unintentional Injuries, 2015, ” available at https://www.nsc.org/Portals/0/
Documents/NSCDocuments_Corporate/estimating-costs.pdf 18   |   Ethics, Technology, and Public Policy – Autonomous VehiclesIn the summer of 2018, the UK passed an Act of Parliament85 that aimed to clarify liability for 
automated vehicles. When “an accident is caused by an automated vehicle… driving itself” and the 
vehicle is insured, the insurer would be directly liable for any damage. The intention was to give 
collision victims a swift path to compensation without pursuing complicated product liability claims 
against car makers or A V software companies. (The insurer could, in turn, sue the manufacturers if it 
wanted to).
However, there are several exclusions and gaps in the legislation. If an insured person alters their 
vehicle’s software without permission – or fails to install critical software updates when required – 
that would exclude liability, as would a person’s “negligence in allowing the vehicle to begin driving 
itself when it was not appropriate to do so.” 
These clauses seem to require consumers to have knowledge about which updates are safety-critical 
and which are not, and to have a good understanding of the operational limitations of their vehicle’s 
automated driving system. The law also fails to consider Level 2 and 3 automated driving systems 
that need monitoring. 
Security, hacking and privacy
A Vs are not just computers on wheels, they are hundreds of computers on wheels. Every one of those 
is prone to the same software bugs, hardware glitches, security flaws and privacy intrusions as your 
phone or laptop, plus some brand new vulnerabilities unique to robotic systems. 
Modern Level 0 and Level 1 vehicles have already proven susceptible to hacking,86 with researchers 
demonstrating an ability to remotely take control of moving cars on the highway.87 These attacks 
have typically exploited vulnerabilities in vehicle’s infotainment systems, gaining access through 
diagnostic ports or even wirelessly using Bluetooth and other radio connections. With more 
computers, more sensors and more connectivity, A Vs will fundamentally offer a larger attack surface 
for those with malicious intent. 
While the security weaknesses of computers are well understood, those of innovative sensor 
systems have been less well tested. Researchers have found that they can fool computer visions into 
misreading Stop signs,88 spoof GPS signals for navigation,89 and even generate fake walls and cars to 
trick lidar systems.90  
The potential consequences of hacking a vehicle are obviously much more serious than seizing 
control of a personal computer. Ransomware takes on a whole new meaning, and the first A Vs to be 
misdirected or forced into a collision could set back the MAAS industry for years.
85 UK Government, “The Automated and Electric Vehicles Act 2018, ” available at http://www.legislation.gov.uk/ukpga/2018/18/
section/2/enacted
86 SANS Institute, “Developments in Car Hacking, ” December 5 2015, available at https://www.sans.org/reading-room/whitepapers/
ICS/developments-car-hacking-36607
87 Andy Greenberg, “Hackers Remotely Kill A Jeep On The Highway – With Me In It, ” Wired, July 21 2015, https://www.wired.
com/2015/07/hackers-remotely-kill-jeep-highway/
88 Mark Harris, “Researchers Find a Malicious Way to Meddle with Autonomous Cars, ” Car And Driver, August 4 2017, https://www.
caranddriver.com/news/researchers-find-a-malicious-way-to-meddle-with-autonomous-cars
89 Jonathan Petit, “ Attacking Automated Vehicles Through GPS Spoofing, ” OnBoard Security, August 22 2018, http://blog.
onboardsecurity.com/blog/attacking-automated-vehicles-through-gps-spoofing
90 Mark Harris, “Researcher Hacks Self-driving Car Sensors, ” IEEE Spectrum, September 4 2015, https://spectrum.ieee.org/cars-that-
think/transportation/self-driving/researcher-hacks-selfdriving-car-sensors Ethics, Technology, and Public Policy – Autonomous Vehicles  |   19This work is licensed under a Creative Commons Attribution 4.0 International License.Among A V developers, Waymo has been the most open about its cybersecurity precautions.91 It 
follows a multi-step approach involving verifiable software, redundant security systems, timely 
updates, encrypted communications, and threat modeling. 
Karl Iagnemma, president of nuTonomy, a company building software for MAAS A Vs, cautions about 
focusing too much on cybersecurity scares, at the cost of over-looking problems designed into the 
system. He says, “The biggest threat to an occupant of a self-driving car today isn’t any hack, it’s the 
bug in someone’s software because we don’t have systems that we’re 100 percent sure are safe.” The 
tragic evidence for this, the death of pedestrian Elaine Herzberg in Tempe under the wheels of an 
Uber A V , shows that A Vs introduce their own modes of failure around automated decision making 
and the human-machine interface. 
A Vs also bring to the fore emerging issues around technology and privacy. “Anytime we get into a 
vehicle, a lot of people will know who’s in the vehicle, where we’ve been, where we’re going and 
what we’re doing. We’re clearly going to live in a much more observed world and that has a lot of 
implications,” says David Dixon, an urban designer and author of a book called Suburban Remix.
If you summon a MAAS A V on your app, you will be sharing at least your current location and 
your destination. The Tesla Model 3 already comes with an internal camera,92 possibly to enable 
monitoring of passengers during future MAAS rides. The Cadillac CT6 also has a driver-facing 
camera, whose function is to track the driver’s head position to see whether they are paying attention 
to the road during Level 2 and 3 automated driving. Upcoming vehicle-to-vehicle (V2V) systems that 
broadcast data for safety reasons also potentially open the door to privacy abuses.93 
In reality, consumers are already making similar privacy sacrifices when participating in ride-share 
services. In addition, the use of a GPS-enabled smartphone also gives navigation service providers 
like Google and Apple detailed insights into our daily movements in our own vehicles.94 The 
development of numerous governmental automated license plate reader (ALPR) systems,95 as well as 
peer-to-peer vehicle tracking dashcams apps,96 mean that even the least tech-savvy individuals are 
likely being tracked and located multiple times a day.
Nevertheless, concentrating such powerful sensor, processing and connectivity technologies in 
something as central to people’s sense of identity as a personal vehicle can produce some startlingly 
dystopian visions. Consider Motorola’s patent for a car that, as one analyst summarizes it, “locks 
you up, administers a breathalyzer, reads you your rights, figures out who your counsel of record is, 
conferences you in with your lawyer, consults with a court on your bail, and lets you swipe your cards 
to bail out of the car.”97
91 Waymo Safety Report, page 19, available at https://waymo.com/safety/
92 Fred Lambert, “Tesla Model 3 is equipped with a driver-facing camera for Autopilot and Tesla Network, ” Electrek, August 1 2017, 
https://electrek.co/2017/08/01/tesla-model-3-driver-facing-camera-autopilot-tesla-network/
93 Electronic Frontier Foundation, “Danger Ahead: The Government’s Plan for Vehicle-to-Vehicle Communication Threatens Privacy, 
Security, and Common Sense, ” May 8 2017, https://www.eff.org/deeplinks/2017/05/danger-ahead-governments-plan-vehicle-vehicle-
communication-threatens-privacy
94 https://www.google.com/maps/timeline?pb
95 Jamela Debelak, “ ALPR: The Surveillance Tool Y ou’ve Probably Never Heard Of, ” ACLU, May 20 2013, https://www.aclu-wa.org/blog/
alpr-surveillance-tool-you-ve-probably-never-heard
96 Mark Harris, “The AI Dashcam App That Wants to Rate Every Driver in the World, ” IEEE Spectrum, June 15 2016, https://spectrum.
ieee.org/cars-that-think/transportation/sensors/the-ai-dashcam-app-that-wants-to-rate-every-driver-in-the-world
97 Cory Doctorow, “Motorola patents a robocop autonomous car that brethalyzes, mirandizes you, calls your lawyer and collects your 
bail, ” BoingBoing, September 9 2018, https://boingboing.net/2018/09/09/i-cant-let-you-do-that-dave-2.html 20   |   Ethics, Technology, and Public Policy – Autonomous VehiclesMadeleine Elish of the Data & Society Research Institute has introduced the concept of the “moral 
crumple zone.”98 Just as a crumple zone in a car absorbs the force of a collision, she worries that the 
human in a robotic system will bear the brunt of the moral and legal penalties when the system fails. 
Ian Kerr, Canada Research Chair in Ethics, Law and Technology at the University of Ottawa, predicts 
that privacy could be the first moral crumple zone in Level 2 and Level 3 semi-automated vehicles. In 
an effort to reduce manufacturers’ liability, he writes: “The use of internal sensors will increase the 
overall personal information collection payload with more and more personal data being collected 
and controlled by the automotive industry.”
But this is not inevitable, argues Kerr. Engineers and policy makers could, and should, strive to 
preserve privacy while ensuring safety. Systems designed to eliminate driver inattention should 
be limited to those functions, even if they are theoretically capable of identifying and tracking 
occupants and other road users, or providing commercially useful data to car makers, advertisers or 
wider data platforms. 
Kerr cites positive policy innovations like Europe’s General Data Protection Regulation (GDPR),99  
which requires companies to implement data protection by default into their products, and Canada’s 
Privacy by Design principles, which highlight privacy, security, visibility and transparency. 100 
The problem with the Trolley Problem
Patrick Lin, a philosopher at the California Polytechnic State University, thinks that developers of 
A V also need to explicitly consider ethics when designing their technologies. In a 2015 paper,101 he 
discussed a philosophical dilemma commonly called “the trolley problem” in the context of A Vs. 
Imagine a light rail streetcar is careering down a hill. On its current course, it will hit and kill a 
pedestrian, but you just have time to divert it to a dead end track, where it will crash and kill its 
occupants. What should you do? 
Lin suggests several 21st-century versions for A Vs. For example, faced with the choice between 
hitting a deer on a country road (the  cause of around 1 million collisions in the US annually) or 
swerving dangerously into oncoming traffic, what would you want your automated vehicle to do? 
Whatever split-second choice humans make in such situations is usually forgiven, as we are usually 
responding instinctively. But an A V has more responsibility, Lin argues: “The programmer and [car 
maker] do not operate under the sanctuary of reasonable instincts; they make potentially life-and-
death decisions under no truly urgent time-constraint and therefore incur the responsibility of 
making better decisions than human drivers reacting reflexively in surprise situations.”102
There are many possible aspects to consider. Should an A V simply attempt to minimize damage to 
the car in any unavoidable crash? But what if that means hitting an innocent cyclist rather than a SUV 
with a drunk driver? Should an A V sacrifice its own passenger rather than crashing into a school bus? 
In 2016, a Mercedes Benz executive said that its future A Vs would be selfish, with a priority on saving 
those inside the vehicle.103
98 M C Elish, “Moral Crumple Zones: Cautionary Tales in Human-Robot Interaction, ” We Robot 2016 working paper, April 3 2016, 
available at https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2757236
99 https://eugdpr.org/
100 Ann Cavoukian, “Privacy By Design, ” Information & Privacy Commissioner Ontario Canada, 2011, https://www.ipc.on.ca/wp-
content/uploads/Resources/7foundationalprinciples.pdf
101 Patrick Lin, “Why Ethics Matters for Autonomous Cars, ” Autonomes Fahren, SpringLink, 2015, available at https://link.springer.
com/content/pdf/10.1007%2F978-3-662-45854-9_4.pdf
102 Ibid p75
103 Michael Taylor, “Self-Driving Mercedes-Benzes Will Prioritize Occupant Safety over Pedestrians, ” Car and Driver, October 7 2016,  Ethics, Technology, and Public Policy – Autonomous Vehicles  |   21This work is licensed under a Creative Commons Attribution 4.0 International License.In 2016, NHTSA’s 15-point Safety Assessment checklist for A Vs included an entire section on ethical 
considerations: 104 “Even in instances in which no explicit ethical rule or preference is intended, the 
programming of an A V may establish an implicit or inherent decision rule with significant ethical 
consequences. Manufacturers and other entities, working cooperatively with regulators and other 
stakeholders (e.g., drivers, passengers and vulnerable road users), should address these situations to 
ensure that such ethical judgments and decisions are made consciously and intentionally.”
To unpack the issue, Iyad Rahwan of MIT’s Media Lab attempted to construct “moral algorithms” 
by crowd-sourcing answers to such dilemmas on Amazon’s Mechanical Turk system.105 He found 
that participants were generally comfortable with purely utilitarian A Vs, programmed to minimize 
a collision’s overall death toll – although they would actually be less likely to buy such an altruistic 
vehicle over one that prioritized their own family in a crash.
Under the Trump administration, a “clearer, more streamlined, less burdensome” NHTSA checklist 
issued in September 2017 dropped the ethical considerations section altogether.106 This fits with the 
thinking of many A V engineers. Karl Iagnemma of nuTonomy sees bigger issues with the deployment 
of A Vs than improbable ethical dilemmas. He believes that “focusing on the trolley problem could 
distract regulators from the important task of ensuring a safe transition to the deployment of A Vs, or 
mislead the public into thinking either that A Vs are programmed to target certain types of people or 
simply that A Vs are dangerous.”107
Johannes Himmelreich is a philosopher in the McCoy Family Center for Ethics in Society at Stanford 
University, and works part-time at Apple on the ethics of machine learning and autonomous systems. 
He argues108 that the trolley problem is not only implausible – presupposing an unavoidable collision, 
and yet enough control to allow its course to be altered – but unrealistic to apply to A Vs, whose 
behavior is often controlled through the ‘bottom-up’ learning of neural networks rather than ‘top-
down’ decision-making. 
Bryant Walker Smith agrees that the binary clarity of the trolley problem is misleading. Drivers, 
whether automated or human, rarely face clear-cut choices and definite outcomes. Instead, driving is 
a social dance where every participant is constantly weighing the safety of themselves and other road 
users with their need to reach their destination, and possibly listening to a conversation or following 
sat-nav directions at the same time.
Our behaviors on the road are the result of complex calculation of possibilities, wrote Smith in 
2017:109 “These cyber-physical systems will need to balance risks rather than merely harms or 
probabilities in isolation. If an automated vehicle will not merge onto a freeway unless ther e is no 
conceivable scenario in which harm may occur, then it will not merge at all.”
https://www.caranddriver.com/news/self-driving-mercedes-will-prioritize-occupant-safety-over-pedestrians
104 Department of Transportation, “Federal Automated Vehicles Policy, ” September 2016, available at https://www.transportation.gov/
sites/dot.gov/files/docs/AV%20policy%20guidance%20PDF.pdf
105 Jean-Francois Bonnefon, Iyad Rahwan, Azim Shariff, “ Autonomous Vehicles Need Experimental Ethics: Are We Ready for Utilitarian 
Cars?” arXiv, October 2015, available at https://www.researchgate.net/publication/282843902_Autonomous_Vehicles_Need_
Experimental_Ethics_Are_We_Ready_for_Utilitarian_Cars
106 NHTSA, “ Automated Driving Systems, ” https://www.nhtsa.gov/manufacturers/automated-driving-systems
107 Karl Iagnemma, nuTonomy, “Why we have the ethics of self-driving cars all wrong, ” World Economic Forum, January 21 2018, 
https://www.weforum.org/agenda/2018/01/why-we-have-the-ethics-of-self-driving-cars-all-wrong
108 Johannes Himmelreich, “Never Mind the Trolley: The Ethics of Autonomous Vehicles in Mundane Situations, ” Ethical Theory and 
Moral Practice, June 2018, available at http://www.johanneshimmelreich.net/wc/uploads/2018/05/Never-Mind-the-Trolley.pdf
109 Bryant Walker Smith, “The Trolley and the Pinto, ” Texas A&M Law Review, June 2017, available at https://papers.ssrn.com/sol3/
papers.cfm?abstract_id=2983000 22   |   Ethics, Technology, and Public Policy – Autonomous VehiclesSmith suggests that the most practical  course of action for A V developers is to share data to enable 
all of them to accurately and consistently assess those probabilities, with federal regulators taking 
responsibility for quantifying and minimizing the harms that will always be present when two-ton 
metal objects are hurtling through the real world. 
Ryan Snyder, Principal of Active Transportation at Transpo Group, a consultancy, notes that 
the ethics of A Vs go far beyond collision avoidance. Deciding how A Vs will interact with transit 
and emergency vehicles, with pedestrians and bicycles, and with the cities they travel through, 
is something that must be programmed into the systems. A Vs can be polite or aggressive, 
environmentally minded or profligate, selfish or community-minded. “There are so many value-
laden decisions going into those decisions,” says Snyder. “This shouldn’t be the decision of one 
engineer or bureaucrat. It should be a community discussion - we need an algorithm board for 
autonomous vehicles.”
Himmelreich formalizes this view by noting that A Vs pose not individual, moral dilemmas but  
political problems, reflecting institutional and social choices. Seen in this light, says Himmelreich, 
the more interesting ethical challenges around A V are actually mundane- but regularly fatal - 
situations such as approaching a crosswalk with limited visibility or trying to turn left against 
oncoming traffic. 
The extent to which A Vs can reduce these kind of everyday road deaths will depend on engineering 
and policy decisions, which come with significant ethical dimensions. Stringent regulations 
requiring A Vs to meet minimum safety standards would likely be accompanied by economic costs 
that could delay deployment. Forced data-sharing between manufacturers might result in more 
consistent improvements across the board, but might give rise to user privacy or intellectual 
property problems. And simply leaving safety choices up to the consumer could result in less safe 
(albeit cheaper or more convenient) vehicles overall. 
Himmelreich also speculates that A Vs could surface different ethical issues in the legal landscape. 
Given that auto makers manufacturers are likely to face an increase in liability exposure with A Vs, he 
notes that they might seek to reduce their exposure by programming cars to drive more cautiously in 
certain areas – such as affluent neighborhoods home to people likely to be awarded higher damages. 
Are policy makers ready to deal with this kind of discriminatory driving behavior, at scale? 
Perhaps the most important takeaway from Himmelreich’s research is the awareness that ethical 
concerns about A Vs are not science fiction, but real challenges facing the industry today. Tesla CEO 
Elon Musk already has a strong position on the ethics of A Vs. As with many of his positions, it is 
controversial. “Writing an article that’s negative, you’re effectively dissuading people from using 
autonomous vehicles, you’re killing people,” he said about journalistic criticisms of Tesla’s Autopilot 
system, during an earnings call in 2016.110 
Musk believed that the Level 2 technologies found in his cars were already making them safer than 
a similar Level 0 vehicle, citing a NHTSA report of fewer airbag deployments (often used as a proxy 
for vehicle collisions) among Tesla vehicles. Without getting into the statistical weeds, NHTSA 
denied having evaluated Tesla’s Autopilot technology or having come to a conclusion about its 
effectiveness.111
110 Hudson Hongo, “Elon Musk Blasts Critical Coverage of Self-Driving Cars, ” Gizmodo, October 19 2016, https://gizmodo.com/elon-
musk-blasts-critical-coverage-of-self-driving-cars-1788000412
111 David Shepardson, “U.S. safety agency says ‘did not assess’ Tesla Autopilot effectiveness, ” Reuters, May 2 2018, https://www.reuters. Ethics, Technology, and Public Policy – Autonomous Vehicles  |   23This work is licensed under a Creative Commons Attribution 4.0 International License.But the philosophical question remains. If and when an A V of whatever automation level is 
demonstrated to experience fewer collisions or fewer fatalities, would it be wrong not to use it? 
Moreover, would it be justified for a government to require the use of such technologies, just as many 
do for basic safety equipment like seat safety belts or, soon, back-up cameras? 
The development and use of all technologies come entangled with ethical considerations. But A Vs are 
unique in that they promise to reshape many aspects of human society and culture at many scales, 
from the personal to planetary. 
Full speed ahead
As in many areas of technology, there is a mismatch between the speed of technical progress in A Vs, 
and that of the regulations, laws and policies meant to shape it. Anthony Levandowski may have left 
Uber in disgrace in 2017 but he is already attracting investors and engineers to his new venture – a 
self-driving truck company that aims to be operating across the US within months of its launch. 
“The only thing that matters is the future,” he told The New Yorker after the Waymo trial. “I don’t 
even know why we study history. It’s entertaining, I guess—the dinosaurs and the Neanderthals 
and the Industrial Revolution, and stuff like that. But what already happened doesn’t really matter. 
You don’t need to know that history to build on what they made. In technology, all that matters is 
tomorrow.”112 
Levandowski’s viewpoint may be controversial but it is one that regulators, politicians and engineers 
must be aware of if they are to have any chance of influencing a technology that promises – and 
threatens – so much.
com/article/us-tesla-autopilot/u-s-safety-agency-says-did-not-assess-tesla-autopilot-effectiveness-idUSKBN1I334A
112 Charles Duhigg, “Did Uber Steal Google’s Intellectual Property?” , The New Y orker, October 22 2018, https://www.newyorker.com/
magazine/2018/10/22/did-uber-steal-googles-intellectual-property 24   |   Ethics, Technology, and Public Policy – Autonomous VehiclesExhibit 1 Nevada Assembly Bill No. 511–Committee on Transportation (excerpt)
AN ACT relating to transportation; providing certain privileges to the owner or long-term lessee of 
a qualified alternative fuel vehicle; authorizing in this State the operation of, and a driver’s license 
endorsement for operators of, autonomous vehicles; providing a penalty; and providing other 
matters properly relating thereto. 
Legislative Counsel’s Digest: 
Existing law authorizes the Department of Transportation to adopt regulations to allow certified low 
emission and energy-efficient vehicles to be operated in a lane on a highway under its jurisdiction 
designated for the preferential use or exclusive use of high-occupancy vehicles. (NRS 484A.463) 
Section 6 of this bill defines the term “qualified alternative fuel vehicle” in such a manner as to 
include within the definition both plug-in vehicles that are powered by an electric motor, and 
vehicles which are powered by an alternative fuel and meet specified federal emissions standards. 
Section 7 of this bill requires that, with limited exceptions, each local authority shall establish a 
parking program for qualified alternative fuel vehicles. Section 7 provides that the owner or long-
term lessee of such a vehicle may: (1) apply to the local authority for a distinctive decal, label or other 
identifier that distinguishes the vehicle from other vehicles; and (2) while displaying the distinctive 
identifier, park the vehicle without the payment of a parking fee at certain times in certain public 
parking lots, parking areas and metered parking zones. Section 10 of this bill authorizes the use of 
a qualified alternative fuel vehicle in high-occupancy vehicle lanes irrespective of the occupancy of 
the vehicle, if the Department of Transportation has adopted the necessary regulations. Section 13 of 
this bill causes the provisions of this bill that pertain to qualified alternative fuel vehicles to expire by 
limitation (“sunset”) as of January 1, 2018. 
Section 8 of this bill requires the Department of Motor Vehicles to adopt regulations authorizing 
the operation of autonomous vehicles on highways within the State of Nevada. Section 8 defines 
an “autonomous vehicle” to mean a motor vehicle that uses artificial intelligence, sensors and 
global positioning system coordinates to drive itself without the active intervention of a human 
operator. Section 2 of this bill requires the Department, by regulation, to establish a driver’s license 
endorsement for the operation of an autonomous vehicle on the highways of this State. 
Sec. 8. 
1. The Department shall adopt regulations authorizing the operation of autonomous vehicles on high -
ways within the State of Nevada. 
2. The regulations required to be adopted by subsection 1 must: 
(a) Set forth requirements that an autonomous vehicle must meet before it may be operated on a high -
way within this State; 
(b) Set forth requirements for the insurance that is required to test or operate an autonomous vehicle 
on a highway within this State; 
(c) Establish minimum safety standards for autonomous vehicles and their operation; 
(d) Provide for the testing of autonomous vehicles; 
(e) Restrict the testing of autonomous vehicles to specified geographic areas; and 
(f) Set forth such other requirements as the Department determines to be necessary. 
3. As used in this section: 
(a) “Artificial intelligence” means the use of computers and related equipment to enable a machine to 
duplicate or mimic the behavior of human beings. 
(b) “Autonomous vehicle” means a motor vehicle that uses artificial intelligence, sensors and global 
positioning system coordinates to drive itself without the active intervention of a human operator. 
(c) “Sensors” includes, without limitation, cameras, lasers and radar .  Ethics, Technology, and Public Policy – Autonomous Vehicles  |   25This work is licensed under a Creative Commons Attribution 4.0 International License.Exhibit 2: Operate Administrations – How US DOT agencies engage with automation
Exhibit 3 – Letter from Department of Transportation Secretary Elaine L. Chao (October 2018)
America has always been a leader in transportation innovation. From the mass production of 
automobiles to global positioning system navigation, American ingenuity has transformed how we 
travel and connect  
with one another. With the development of automated vehicles, American creativity and innovation 
hold the potential to once again transform mobility. 
Automation has the potential to improve our quality of life and enhance the mobility and 
independence of millions of Americans, especially older Americans and people  
with disabilities. 
Moreover, the integration of automation across our transportation system has the potential  
to increase productivity and facilitate freight movement. But most importantly, automation has 
the potential to impact safety significantly— by reducing crashes caused by human error, including 
crashes involving impaired or distracted drivers, and saving lives. 
Along with potential benefits, however, automation brings new challenges that need to be addressed. 
The public has legitimate concerns about the safety, security, and privacy of automated technology. 
So I have challenged Silicon Valley and other innovators to step up and help address these concerns 
and help inform the public about the bene ts  
of automation. In addition, incorporating these technologies into our transportation systems may 
impact industries, creating new kinds of jobs. This technology evolution may also require workers 
in transportation elds to gain new skills and take on new roles. As a society, we must help prepare 
workers for this transition. 
 26   |   Ethics, Technology, and Public Policy – Autonomous VehiclesThe U.S. Department of Transportation is taking active steps to prepare for the future by engaging 
with new technologies to ensure safety without hampering innovation. With the release of 
Automated Driving Systems 2.0: A Vision for Safety in September 2017, the Department provided 
voluntary guidance to industry, as well as technical assistance and best practices to States, offering 
a path forward for the safe testing and integration of automated driving systems. The Department 
also bolstered its engagement with the automotive industry, technology companies, and other key 
transportation stakeholders and innovators to continue to develop a policy framework that facilitates 
the safe integration of this technology into our transportation systems. 
Preparing for the Future of Transportation: Automated Vehicles 3.0 (A V 3.0) is another milestone 
in the Department’s development of a exible, responsible approach to a framework for multimodal 
automation. It introduces guiding principles and describes the Department’s strategy to address 
existing barriers to safety innovation and progress. It also communicates the Department’s agenda to 
the public and stakeholders on important policy issues, and identi es opportunities for cross-modal 
collaboration. 
The Department is committed to engaging stakeholders to identify and solve policy issues. Since 
the publication of Automated Driving Systems 2.0: A Vision for Safety, the Department has sought 
input on automation issues from stakeholders and the general public through a wide range of forums 
including formal Requests 
for Information and Comments. In March 2018, I hosted the Automated Vehicle Summit to present 
the Department’s six Automation Principles and discuss automation issues  
with public and private sector transportation stakeholders across every mode. The ideas and 
issues raised by stakeholders through these forums are re ected in this document. The goal of the 
Department is to keep pace with these rapidly evolving technologies so America remains a global 
leader in safe automation technology. 
A V 3.0 is the beginning of a national discussion about the future of our surface transportation 
system. Your voice is essential to shaping this future. 
Secretary Elaine L. Chao Ethics, Technology, and Public Policy – Autonomous Vehicles  |   27This work is licensed under a Creative Commons Attribution 4.0 International License.Exhibit 4 – Safety by the Numbers (US DOT)
 28   |   Ethics, Technology, and Public Policy – Autonomous VehiclesExhibit 5 – Waymo Safety Report: Basic Behavioral Competency Testing 
We believe that our fully self-driving vehicles should be able to successfully demonstrate competency 
in a variety of reasonably foreseeable traffic situations that are within the vehicle’s operational design 
domain. Our system can recognize and stay within its design domain, and the set of competencies 
expands or shrinks in accordance with the scope of each operational design domain. For each 
behavioral competency shown in the table below, we test a wide range of scenarios with variations in 
factors such as road configuration, the speed of our vehicle or other vehicles, and lighting conditions. 
27 Set of Behavioral Competencies Recommended by NHTSA  
1  Detect and Respond to Speed Limit Changes and Speed Advisories  
2  Perform High -Speed Merge (e.g., Freeway)  
3  Perform Low -Speed Merge  
4  Move Out of the Travel Lane and Park (e.g., to the Shoulder for Minimal Risk)  
5  Detect and Respond to Encroaching Oncoming Vehicles  
6  Detect Passing and No Passing Zones and Perform Passing Maneuvers  
7  Perform Car Following (Including Stop and Go)  
8  Detect and Respond to Stopped Vehicles  
9  Detect and Respond to Lane Change s  
10  Detect and Respond to Static Obstacles in the Path of the Vehicle  
11  Detect Tra ck Signals and Stop/Yield Signs  
12  Respond to Tra ck Signals and Stop/Yield Signs  
13  Navigate Intersections and Perform Turns  
14  Navigate Roundabouts  
15  Navigate a Parking Lot and Locate Spaces  
16  Detect and Respond to Access Restrictions (One -Way, No Turn, Ramps, etc.)  
17  Detect and Respond to Work Zones and People Directing Tra ck in Unplanned or Planned Events  
18  Make Appropriate Right -of-Way Decisions  
19 Follow Local and State Driving Laws  
20  Follow Police/First Responder Controlling Tra ck (Overriding or Acting as Tra ck Control Device)  
21  Follow Construction Zone Workers Controlling Tra ck Patterns (Slow/Stop Sign Holders)  
22  Respond to Citizens Directing Tra ck After a Crash  
23  Detect a nd Respond to Temporary Tra ck Control Devices  
24  Detect and Respond to Emergency Vehicles  
25  Yield for Law Enforcement, EMT, Fire, and Other Emergency Vehicles at Intersections, Junctions, and Other Tra ck Controlled Situations  
26  Yield to Pedestrians and Bicyclists at Intersections and Crosswalks  
27  Provide Safe Distance from  Vehicles, Pedestrians, Bicyclists on Side of the Road  
28  Detect/Respond to Detours and/or Other Temporary Changes in Tra ck Patterns  
Examples of Additional Behavioral Competencies Tested by Waymo  
29  Moving to a Minimum Risk Condition When Exiting the Travel Lane is Not Possible  
30  Perform Lane Changes  
31  Detect and Respond to Lead Vehicle  
32  Detect and Respond to a Merging Vehicle  
33  Detect and Respond to Pedestrians in Road (Not Walking Through Intersection or Crosswalk)  
34  Provide Safe Distance from Bicyclists Traveling on Road (With or Without Bike Lane)  
35  Detect and Respond to An imals  
36  Detect and Respond to Motorcyclists  
37  Detect and Respond to School Buses  
38  Navigate Around Unexpected Road Closures (e.g. Lane, Intersection, etc.)  
39  Navigate Railroad Crossings  
40  Make Appropriate Reversing Maneuvers  
41  Detect and Respond to Vehicle Control Loss (e.g. reduced road friction)  
42  Detect and Respond to Conditions Involving Vehicle, System, or Component -Level Failures or Faults (e.g. power failure, sensing failure, sensing 
obstruction, computing failure, fault handling or response)  
43  Detect and Respond to Unanticipated Weather or  Lighting Conditions Outside of Vehicle’s Capability (e.g. rainstorm)  
44  Detect and Respond to Unanticipated Lighting Conditions (e.g. power outages)  
45  Detect and Respond to Non -Collision Safety Situations (e.g. vehicle doors ajar)  
46  Detect and Respond to Faded or Missing Roadway Markings or Signage  
47  Detect and Respond to Vehicles Parking in the Roadway  
 
 
 
  Ethics, Technology, and Public Policy – Autonomous Vehicles  |   29This work is licensed under a Creative Commons Attribution 4.0 International License.
Exhibit 6 – Uber ATG HardwareThis work is licensed under a Creative Commons Attribution 4.0 International License.